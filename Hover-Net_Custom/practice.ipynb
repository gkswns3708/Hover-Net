{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader import trainloader\n",
    "from models.base_hovernet import targets\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import importlib\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import normal_Config, uniform_Config\n",
    "from termcolor import colored\n",
    "from collections import OrderedDict\n",
    "from models.base_hovernet.utils import crop_to_shape, dice_loss, mse_loss, msge_loss, xentropy_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normal_Config['shape_info'][normal_Config['run_mode']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "# Set random seed\n",
    "torch.manual_seed(normal_Config['seed'])\n",
    "np.random.seed(normal_Config['seed'])\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "run_mode  = normal_Config['run_mode']\n",
    "input_dataset = trainloader.FileLoader(\n",
    "    glob(os.path.join(normal_Config['train_dataset_path'], '*.npy')),     \n",
    "    mode=normal_Config['run_mode'],\n",
    "    with_type=normal_Config['with_type'],\n",
    "    setup_augmentor=True, # 이거 True / False 차이 알아보기\n",
    "    target_gen=[targets.gen_targets, {}],\n",
    "    **normal_Config['shape_info'][normal_Config['run_mode']]\n",
    ")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    input_dataset,\n",
    "    num_workers=2,\n",
    "    batch_size=normal_Config['batch_size'],\n",
    "    shuffle=normal_Config['run_mode'] == \"train\",\n",
    "    drop_last=normal_Config['run_mode'] == \"train\",\n",
    "    # worker_init_fn=worker_init_fn, # TODO: multiGPU에서 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dict_keys(['img', 'tp_map', 'hv_map', 'np_map'])\n",
    "# print(len(input_dataset))\n",
    "# indices = [i for i in range(len(input_dataset))]  # 확인하고 싶은 index 리스트\n",
    "# unique_values = np.unique(np.concatenate([input_dataset[i]['tp_map'].flatten() for i in indices]))\n",
    "# print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module = importlib.import_module(\n",
    "#     \"models.%s.opt\" % normal_Config['model_name']\n",
    "# )\n",
    "# model_config = module.get_config(normal_Config['nr_type'], normal_Config['model_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_hovernet.opt import get_config\n",
    "from models.base_hovernet.net_desc import create_model\n",
    "\n",
    "temp = get_config(8, 'train')\n",
    "for i in range(len(temp['phase_list'])):\n",
    "    print(temp['phase_list'][i]['run_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_type = 8\n",
    "mode = 'original'\n",
    "first_phase_model = create_model(\n",
    "    input_ch=3, nr_types=nr_type, \n",
    "    freeze=True, mode=mode\n",
    "),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_func_dict = {\n",
    "        \"bce\": xentropy_loss,\n",
    "        \"dice\": dice_loss,\n",
    "        \"mse\": mse_loss,\n",
    "        \"msge\": msge_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pytorch_checkpoint(net_state_dict):\n",
    "    variable_name_list = list(net_state_dict.keys())\n",
    "    is_in_parallel_mode = all(v.split(\".\")[0] == \"module\" for v in variable_name_list)\n",
    "    if is_in_parallel_mode:\n",
    "        colored_word = colored(\"WARNING\", color=\"red\", attrs=[\"bold\"])\n",
    "        print(\n",
    "            (\n",
    "                \"%s: Detect checkpoint saved in data-parallel mode.\"\n",
    "                \" Converting saved model to single GPU mode.\" % colored_word\n",
    "            ).rjust(80)\n",
    "        )\n",
    "        net_state_dict = {\n",
    "            \".\".join(k.split(\".\")[1:]): v for k, v in net_state_dict.items()\n",
    "        }\n",
    "    return net_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, pretrained_path, device=\"cuda\"):\n",
    "    if pretrained_path is not None:\n",
    "        print(\"Pretrained Path: \", pretrained_path)\n",
    "        net_state_dict = torch.load(pretrained_path, map_location=device)[\"desc\"]\n",
    "        \n",
    "        # Convert PyTorch checkpoint if necessary\n",
    "        net_state_dict = convert_pytorch_checkpoint(net_state_dict)\n",
    "        \n",
    "        # Load state dict to the model\n",
    "        load_feedback = model.load_state_dict(net_state_dict, strict=False)\n",
    "        print(\"Missing Variables: \\n\", load_feedback[0])\n",
    "        print(\"Detected Unknown Variables: \\n\", load_feedback[1])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "def validate(model, valid_loader, loss_opts, loss_func_dict, device=\"cuda\"):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # 검증 중에는 Gradient 계산을 하지 않음\n",
    "        pbar = tqdm(valid_loader, desc=\"Validation\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            imgs = batch[\"img\"].permute(0, 3, 1, 2).to(device)\n",
    "            true_np = batch[\"np_map\"].to(device)\n",
    "            true_hv = batch[\"hv_map\"].to(device)\n",
    "            true_tp = batch.get(\"tp_map\", None)\n",
    "            if true_tp is not None:\n",
    "                true_tp = true_tp.to(device)\n",
    "\n",
    "            pred_dict = model(imgs)\n",
    "            pred_dict = OrderedDict(\n",
    "                [[k, v.permute(0, 2, 3, 1).contiguous()] for k, v in pred_dict.items()]\n",
    "            )\n",
    "            pred_dict[\"np\"] = torch.softmax(pred_dict[\"np\"], dim=-1)\n",
    "            if \"tp\" in pred_dict:\n",
    "                pred_dict[\"tp\"] = torch.softmax(pred_dict[\"tp\"], dim=-1)\n",
    "\n",
    "            loss = 0\n",
    "            for branch_name, losses in loss_opts.items():\n",
    "                for loss_name, weight in losses.items():\n",
    "                    loss_func = loss_func_dict[loss_name]\n",
    "\n",
    "                    if branch_name == \"np\":\n",
    "                        pred_np = pred_dict[\"np\"][..., 1]\n",
    "                        true_np = true_np.to(torch.int64)\n",
    "                        true_np_onehot = F.one_hot(true_np, num_classes=2).type(torch.float32)\n",
    "                        loss += weight * loss_func(pred_np, true_np_onehot[..., 1])\n",
    "\n",
    "                    elif branch_name == \"hv\":\n",
    "                        pred_hv = pred_dict[\"hv\"]\n",
    "                        if loss_name == \"msge\":\n",
    "                            focus = true_np_onehot[..., 1]\n",
    "                            loss += weight * loss_func(pred_hv, true_hv, focus)\n",
    "                        else:\n",
    "                            loss += weight * loss_func(pred_hv, true_hv)\n",
    "\n",
    "                    elif branch_name == \"tp\" and true_tp is not None:\n",
    "                        pred_tp = pred_dict[\"tp\"].permute(0, 3, 1, 2)\n",
    "                        if not true_tp.dtype == torch.int64:\n",
    "                            true_tp = true_tp.to(torch.int64)\n",
    "\n",
    "                        true_tp_onehot = F.one_hot(true_tp, num_classes=pred_tp.shape[1])\n",
    "                        true_tp_onehot = true_tp_onehot.permute(0, 3, 1, 2).type(torch.float32)\n",
    "                        loss += weight * loss_func(pred_tp, true_tp_onehot)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# ✅ 모델 초기화 개선 함수 (He Initialization 사용)\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def train_phase(config, phase_idx, model=None, model_path=None, device=\"cuda\"):\n",
    "    phase_info = config[\"phase_list\"][phase_idx]\n",
    "    run_info = phase_info[\"run_info\"]\n",
    "    net_info = run_info[\"net\"]\n",
    "\n",
    "    # 모델 초기화 (Phase 1이면 모델 새로 생성, Phase 2면 기존 모델 이어받기)\n",
    "    if model is None:\n",
    "        model = net_info[\"desc\"]().to(device)\n",
    "        model.apply(initialize_weights)  # ✅ 모델 초기화 적용 (He Initialization)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    optimizer_class, optimizer_params = net_info[\"optimizer\"]\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_params)\n",
    "    scheduler = net_info[\"lr_scheduler\"](optimizer)\n",
    "\n",
    "    loss_opts = net_info[\"extra_info\"][\"loss\"]\n",
    "    loss_func_dict = {\n",
    "        \"bce\": xentropy_loss,\n",
    "        \"dice\": dice_loss,\n",
    "        \"mse\": mse_loss,\n",
    "        \"msge\": msge_loss,\n",
    "    }\n",
    "\n",
    "    pretrained_path = net_info[\"pretrained\"]\n",
    "    if pretrained_path != -1 and pretrained_path is not None:\n",
    "        if phase_idx == 0:\n",
    "            state_dict = torch.load(pretrained_path, map_location=device)[\"desc\"]\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "        elif phase_idx == 1 and model_path is not None:\n",
    "            checkpoint_path = f\"{model_path}/phase1_model.pth\"\n",
    "            state_dict = torch.load(checkpoint_path, map_location=device)[\"desc\"]\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    train_dataset = trainloader.FileLoader(\n",
    "        glob(os.path.join(normal_Config['train_dataset_path'], '*.npy')),     \n",
    "        mode=normal_Config['run_mode'],\n",
    "        with_type=normal_Config['with_type'],\n",
    "        setup_augmentor=True, # 이거 True / False 차이 알아보기\n",
    "        target_gen=[targets.gen_targets, {}],\n",
    "        **normal_Config['shape_info'][normal_Config['run_mode']]\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        num_workers=2,\n",
    "        batch_size=normal_Config['batch_size'],\n",
    "        shuffle=normal_Config['run_mode'] == \"train\",\n",
    "        drop_last=normal_Config['run_mode'] == \"train\",\n",
    "        # worker_init_fn=worker_init_fn, # TODO: multiGPU에서 \n",
    "    )\n",
    "    \n",
    "    print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
    "    for key, value in train_dataset[0].items():\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "    \n",
    "    valid_dataset = trainloader.FileLoader(\n",
    "        glob(os.path.join(normal_Config['valid_dataset_path'], '*.npy')),     \n",
    "        mode=normal_Config['run_mode'],\n",
    "        with_type=normal_Config['with_type'],\n",
    "        setup_augmentor=True, # 이거 True / False 차이 알아보기\n",
    "        target_gen=[targets.gen_targets, {}],\n",
    "        **normal_Config['shape_info'][normal_Config['run_mode']]\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        num_workers=2,\n",
    "        batch_size=normal_Config['batch_size'],\n",
    "        shuffle=normal_Config['run_mode'] == \"train\",\n",
    "        drop_last=normal_Config['run_mode'] == \"train\",\n",
    "        # worker_init_fn=worker_init_fn, # TODO: multiGPU에서 \n",
    "    )\n",
    "\n",
    "    nr_epochs = phase_info[\"nr_epochs\"]\n",
    "    for epoch in range(nr_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            imgs = batch[\"img\"].permute(0, 3, 1, 2).to(device)\n",
    "            true_np = batch[\"np_map\"].to(device)\n",
    "            true_hv = batch[\"hv_map\"].to(device)\n",
    "            true_tp = batch.get(\"tp_map\", None)\n",
    "            if true_tp is not None:\n",
    "                true_tp = true_tp.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_dict = model(imgs)\n",
    "            pred_dict = {k: v.permute(0, 2, 3, 1) for k, v in pred_dict.items()}\n",
    "            for key, value in pred_dict.items():\n",
    "                print(f\"Predicted {key} Shape: {value.shape}\")\n",
    "            \n",
    "            loss = 0\n",
    "            for branch_name, losses in loss_opts.items():\n",
    "                for loss_name, weight in losses.items():\n",
    "                    loss_func = loss_func_dict[loss_name]\n",
    "\n",
    "                    if branch_name == \"np\":\n",
    "                        # ✅ np Branch: Binary Classification (Softmax 적용 후 그대로 사용)\n",
    "                        pred_np = torch.softmax(pred_dict[\"np\"], dim=-1)  # Softmax 적용 (dim=-1)\n",
    "                        print(f\"[Branch: np] - After Softmax Shape: {pred_np.shape}\")  # Expected: (B, W, H, 2)\n",
    "                        \n",
    "                        true_np = true_np.to(torch.int64)\n",
    "                        true_np_onehot = F.one_hot(true_np, num_classes=2).type(torch.float32)  # Shape: (B, W, H, 2)\n",
    "                        \n",
    "                        if loss_name == \"bce\":\n",
    "                            np_loss = weight * loss_func(pred_np, true_np_onehot)\n",
    "                        elif loss_name == \"dice\":\n",
    "                            np_loss = weight * loss_func(true_np_onehot, pred_np)\n",
    "                        \n",
    "                        loss += np_loss\n",
    "                        \n",
    "                        # Debug Output\n",
    "                        print(f\"[Branch: np] - Predicted Shape: {pred_np.shape}\")\n",
    "                        print(f\"[Branch: np] - Label Shape: {true_np.shape}\")\n",
    "                        print(f\"Branch: np, Loss: {loss_name}, Weight: {weight}, Loss Value: {np_loss.item()}\")\n",
    "\n",
    "                    elif branch_name == \"hv\":\n",
    "                        # ✅ hv Branch: Regression Task (Horizontal & Vertical Gradients)\n",
    "                        pred_hv = pred_dict[\"hv\"]  # Output shape: (B, W, H, 2)\n",
    "                        true_hv_x = true_hv[..., 0]  # Shape: (B, W, H)\n",
    "                        true_hv_y = true_hv[..., 1]  # Shape: (B, W, H)\n",
    "                        pred_hv_x = pred_hv[..., 0]  # Shape: (B, W, H)\n",
    "                        pred_hv_y = pred_hv[..., 1]  # Shape: (B, W, H)\n",
    "\n",
    "                        if loss_name == \"msge\":\n",
    "                            focus = true_np_onehot[..., 1]  # Positive mask\n",
    "                            hv_loss = weight * loss_func(true_hv, pred_hv, focus)\n",
    "                        else:  # mse loss\n",
    "                            hv_loss_x = weight * loss_func(pred_hv_x, true_hv_x)\n",
    "                            hv_loss_y = weight * loss_func(pred_hv_y, true_hv_y)\n",
    "                            hv_loss = (hv_loss_x + hv_loss_y) / 2\n",
    "                        \n",
    "                        loss += hv_loss\n",
    "                        \n",
    "                        # Debug Output\n",
    "                        print(f\"[Branch: hv] - Predicted Shape: {pred_hv.shape}\")\n",
    "                        print(f\"[Branch: hv] - Label Shape: {true_hv.shape}\")\n",
    "                        print(f\"Branch: hv, Loss: {loss_name}, Weight: {weight}, Loss Value: {hv_loss.item()}\")\n",
    "\n",
    "                    elif branch_name == \"tp\":\n",
    "                        # ✅ tp Branch: Multi-Class Classification (e.g., 8 classes)\n",
    "                        pred_tp = torch.softmax(pred_dict[\"tp\"], dim=-1)  # Output shape: (B, W, H, 8)\n",
    "                        true_tp = true_tp.to(torch.int64)\n",
    "                        true_tp_onehot = F.one_hot(true_tp, num_classes=8).type(torch.float32)  # Shape: (B, W, H, 8)\n",
    "                        \n",
    "                        if loss_name == \"bce\":\n",
    "                            tp_loss = weight * loss_func(pred_tp, true_tp_onehot)\n",
    "                        elif loss_name == \"dice\":\n",
    "                            tp_loss = weight * loss_func(true_tp_onehot, pred_tp)\n",
    "                        \n",
    "                        loss += tp_loss\n",
    "                        \n",
    "                        # Debug Output\n",
    "                        print(f\"[Branch: tp] - Predicted Shape: {pred_tp.shape}\")\n",
    "                        print(f\"[Branch: tp] - Label Shape: {true_tp.shape}\")\n",
    "                        print(f\"Branch: tp, Loss: {loss_name}, Weight: {weight}, Loss Value: {tp_loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # ✅ Gradient Clipping 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{nr_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    config = get_config(8, 'original')\n",
    "\n",
    "    # Phase 1 학습\n",
    "    model = train_phase(config, phase_idx=0, model_path=\"./checkpoints\")\n",
    "    \n",
    "    # Phase 2 학습 (Phase 1 모델을 이어받음)\n",
    "    model = train_phase(config, phase_idx=1, model=model, model_path=\"./checkpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Phase 1 모델 로드 완료\n",
      "✅ Phase 2 모델 로드 완료\n",
      "\n",
      "🔍 Phase 1 Model Structure and Weight Shapes:\n",
      "Layer: conv0./.weight | Shape: torch.Size([64, 3, 7, 7]) | Requires Grad: True\n",
      "Layer: conv0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: conv0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1.weight | Shape: torch.Size([64, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.shortcut.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.shortcut.weight | Shape: torch.Size([512, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1.weight | Shape: torch.Size([256, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.shortcut.weight | Shape: torch.Size([1024, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1.weight | Shape: torch.Size([512, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.shortcut.weight | Shape: torch.Size([2048, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: conv_bot.weight | Shape: torch.Size([1024, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.weight | Shape: torch.Size([8, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.bias | Shape: torch.Size([8]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 Phase 2 Model Structure and Weight Shapes:\n",
      "Layer: conv0./.weight | Shape: torch.Size([64, 3, 7, 7]) | Requires Grad: True\n",
      "Layer: conv0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: conv0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1.weight | Shape: torch.Size([64, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.shortcut.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.shortcut.weight | Shape: torch.Size([512, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1.weight | Shape: torch.Size([256, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.shortcut.weight | Shape: torch.Size([1024, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1.weight | Shape: torch.Size([512, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.shortcut.weight | Shape: torch.Size([2048, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: conv_bot.weight | Shape: torch.Size([1024, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.weight | Shape: torch.Size([8, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.bias | Shape: torch.Size([8]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from models.base_hovernet.opt import get_config\n",
    "\n",
    "# ✅ 모델 경로 설정\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "phase1_path = os.path.join(checkpoint_dir, \"phase1_model.tar\")\n",
    "phase2_path = os.path.join(checkpoint_dir, \"phase2_model.tar\")\n",
    "\n",
    "# ✅ 모델 로딩 함수 (모델 구조를 그대로 보기 위해 Strict=True 사용 안함)\n",
    "def load_model(model_path, model_class, device=\"cuda\"):\n",
    "    model = model_class().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ✅ Config 로드\n",
    "config = get_config(8, 'original')\n",
    "net_info = config[\"phase_list\"][0][\"run_info\"][\"net\"]\n",
    "\n",
    "# ✅ 모델 클래스 정의 (HoverNet 모델 로딩)\n",
    "model_class = net_info[\"desc\"]\n",
    "\n",
    "# ✅ Phase 1 모델 로드\n",
    "phase1_model = load_model(phase1_path, model_class, device=\"cuda\")\n",
    "print(\"✅ Phase 1 모델 로드 완료\")\n",
    "\n",
    "# ✅ Phase 2 모델 로드\n",
    "phase2_model = load_model(phase2_path, model_class, device=\"cuda\")\n",
    "print(\"✅ Phase 2 모델 로드 완료\")\n",
    "\n",
    "# ✅ 모델의 Layer와 Weight Shape 확인 함수\n",
    "def print_model_structure(model, model_name=\"Model\"):\n",
    "    print(f\"\\n🔍 {model_name} Structure and Weight Shapes:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Shape: {param.shape} | Requires Grad: {param.requires_grad}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ✅ Phase 1 모델 구조 확인\n",
    "print_model_structure(phase1_model, model_name=\"Phase 1 Model\")\n",
    "\n",
    "# ✅ Phase 2 모델 구조 확인\n",
    "print_model_structure(phase2_model, model_name=\"Phase 2 Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 원본 모델 로드 완료\n",
      "\n",
      "🔍 Original Model Structure and Weight Shapes:\n",
      "Layer: conv0./.weight | Shape: torch.Size([64, 3, 7, 7]) | Requires Grad: True\n",
      "Layer: conv0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: conv0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1.weight | Shape: torch.Size([64, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.0.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.1.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.preact/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1.weight | Shape: torch.Size([64, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv1/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2.weight | Shape: torch.Size([64, 64, 3, 3]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv2/bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: d0.units.2.conv3.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.shortcut.weight | Shape: torch.Size([256, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d0.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.0.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.1.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.2.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.preact/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1.weight | Shape: torch.Size([128, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2.weight | Shape: torch.Size([128, 128, 3, 3]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv2/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: d1.units.3.conv3.weight | Shape: torch.Size([512, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.shortcut.weight | Shape: torch.Size([512, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d1.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1.weight | Shape: torch.Size([256, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.0.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.1.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.2.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.3.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.4.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.preact/bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1.weight | Shape: torch.Size([256, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv1/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2.weight | Shape: torch.Size([256, 256, 3, 3]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv2/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: d2.units.5.conv3.weight | Shape: torch.Size([1024, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.shortcut.weight | Shape: torch.Size([1024, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.weight | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d2.blk_bna.bn.bias | Shape: torch.Size([1024]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1.weight | Shape: torch.Size([512, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.0.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.1.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.preact/bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1.weight | Shape: torch.Size([512, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv1/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2.weight | Shape: torch.Size([512, 512, 3, 3]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv2/bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: d3.units.2.conv3.weight | Shape: torch.Size([2048, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.shortcut.weight | Shape: torch.Size([2048, 1024, 1, 1]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.weight | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: d3.blk_bna.bn.bias | Shape: torch.Size([2048]) | Requires Grad: True\n",
      "Layer: conv_bot.weight | Shape: torch.Size([1024, 2048, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.tp.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.tp.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.weight | Shape: torch.Size([8, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.tp.u0.conv.bias | Shape: torch.Size([8]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.np.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.np.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.np.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.conva.weight | Shape: torch.Size([256, 1024, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([288]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1.weight | Shape: torch.Size([128, 288, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([320]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1.weight | Shape: torch.Size([128, 320, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([352]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1.weight | Shape: torch.Size([128, 352, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.weight | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.preact_bna/bn.bias | Shape: torch.Size([384]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1.weight | Shape: torch.Size([128, 384, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.4.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.weight | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.preact_bna/bn.bias | Shape: torch.Size([416]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1.weight | Shape: torch.Size([128, 416, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.5.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.weight | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.preact_bna/bn.bias | Shape: torch.Size([448]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1.weight | Shape: torch.Size([128, 448, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.6.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.weight | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.preact_bna/bn.bias | Shape: torch.Size([480]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1.weight | Shape: torch.Size([128, 480, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.units.7.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.weight | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.dense.blk_bna.bn.bias | Shape: torch.Size([512]) | Requires Grad: True\n",
      "Layer: decoder.hv.u3.convf.weight | Shape: torch.Size([512, 512, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.conva.weight | Shape: torch.Size([128, 512, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.preact_bna/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1.weight | Shape: torch.Size([128, 128, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.0.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.weight | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.preact_bna/bn.bias | Shape: torch.Size([160]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1.weight | Shape: torch.Size([128, 160, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.1.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.weight | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.preact_bna/bn.bias | Shape: torch.Size([192]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1.weight | Shape: torch.Size([128, 192, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.2.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.weight | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.preact_bna/bn.bias | Shape: torch.Size([224]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1.weight | Shape: torch.Size([128, 224, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.weight | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv1/bn.bias | Shape: torch.Size([128]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.units.3.conv2.weight | Shape: torch.Size([32, 32, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.weight | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.dense.blk_bna.bn.bias | Shape: torch.Size([256]) | Requires Grad: True\n",
      "Layer: decoder.hv.u2.convf.weight | Shape: torch.Size([256, 256, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u1.conva.weight | Shape: torch.Size([64, 256, 5, 5]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.weight | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.bn.bias | Shape: torch.Size([64]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.weight | Shape: torch.Size([2, 64, 1, 1]) | Requires Grad: True\n",
      "Layer: decoder.hv.u0.conv.bias | Shape: torch.Size([2]) | Requires Grad: True\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# ✅ 원본 코드에서 저장된 모델 경로 설정\n",
    "original_model_path = \"/mnt/Hover-Net/Hover-Net_original/logs/05/net_epoch=1.tar\"  # 원본 코드 모델 경로를 여기에 넣으세요\n",
    "\n",
    "# ✅ 모델 로딩 함수 (원본 코드 모델 로딩)\n",
    "def load_original_model(model_path, model_class, device=\"cuda\"):\n",
    "    model = model_class().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ✅ Config 로드 (원본 모델의 config 정보로 수정)\n",
    "config = get_config(8, 'original')\n",
    "net_info = config[\"phase_list\"][0][\"run_info\"][\"net\"]\n",
    "\n",
    "# ✅ 모델 클래스 정의 (원본 HoverNet 모델)\n",
    "model_class = net_info[\"desc\"]\n",
    "\n",
    "# ✅ 원본 모델 로드\n",
    "original_model = load_original_model(original_model_path, model_class, device=\"cuda\")\n",
    "print(\"✅ 원본 모델 로드 완료\")\n",
    "\n",
    "# ✅ 모델의 Layer와 Weight Shape 확인 함수\n",
    "def print_model_structure(model, model_name=\"Model\"):\n",
    "    print(f\"\\n🔍 {model_name} Structure and Weight Shapes:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Shape: {param.shape} | Requires Grad: {param.requires_grad}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ✅ 원본 모델 구조 확인\n",
    "print_model_structure(original_model, model_name=\"Original Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ✅ 모델 구조와 파라미터 Shape 비교 함수\n",
    "def compare_models(model1, model2, model1_name=\"Model 1\", model2_name=\"Model 2\"):\n",
    "    # 모델 1의 Layer 정보 가져오기\n",
    "    model1_layers = {name: param.shape for name, param in model1.named_parameters()}\n",
    "    model1_requires_grad = {name: param.requires_grad for name, param in model1.named_parameters()}\n",
    "    \n",
    "    # 모델 2의 Layer 정보 가져오기\n",
    "    model2_layers = {name: param.shape for name, param in model2.named_parameters()}\n",
    "    model2_requires_grad = {name: param.requires_grad for name, param in model2.named_parameters()}\n",
    "    \n",
    "    # 모델 구조 차이 확인\n",
    "    model1_keys = set(model1_layers.keys())\n",
    "    model2_keys = set(model2_layers.keys())\n",
    "    \n",
    "    only_in_model1 = model1_keys - model2_keys\n",
    "    only_in_model2 = model2_keys - model1_keys\n",
    "    common_keys = model1_keys & model2_keys\n",
    "\n",
    "    print(f\"\\n🔍 Comparing {model1_name} and {model2_name}\\n\")\n",
    "    \n",
    "    if only_in_model1:\n",
    "        print(f\"⚠️ Layers only in {model1_name}: {only_in_model1}\")\n",
    "    if only_in_model2:\n",
    "        print(f\"⚠️ Layers only in {model2_name}: {only_in_model2}\")\n",
    "    \n",
    "    if not only_in_model1 and not only_in_model2:\n",
    "        print(\"✅ Both models have the same layers.\")\n",
    "    \n",
    "    # Shape & requires_grad 비교\n",
    "    mismatched_shapes = []\n",
    "    requires_grad_diff = []\n",
    "    \n",
    "    for key in common_keys:\n",
    "        if model1_layers[key] != model2_layers[key]:\n",
    "            mismatched_shapes.append((key, model1_layers[key], model2_layers[key]))\n",
    "        \n",
    "        if model1_requires_grad[key] != model2_requires_grad[key]:\n",
    "            requires_grad_diff.append((key, model1_requires_grad[key], model2_requires_grad[key]))\n",
    "    \n",
    "    # Shape mismatch 출력\n",
    "    if mismatched_shapes:\n",
    "        print(\"\\n⚠️ Layer Shape Mismatches:\")\n",
    "        for key, shape1, shape2 in mismatched_shapes:\n",
    "            print(f\"  - Layer: {key} | {model1_name} Shape: {shape1} | {model2_name} Shape: {shape2}\")\n",
    "    else:\n",
    "        print(\"\\n✅ All layers have matching shapes.\")\n",
    "    \n",
    "    # Requires_grad mismatch 출력\n",
    "    if requires_grad_diff:\n",
    "        print(\"\\n⚠️ Requires Grad Differences:\")\n",
    "        for key, req1, req2 in requires_grad_diff:\n",
    "            print(f\"  - Layer: {key} | {model1_name} requires_grad: {req1} | {model2_name} requires_grad: {req2}\")\n",
    "    else:\n",
    "        print(\"\\n✅ All layers have matching requires_grad settings.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Comparing My Model (Phase 1) and Original Model (Phase 2)\n",
      "\n",
      "✅ Both models have the same layers.\n",
      "\n",
      "✅ All layers have matching shapes.\n",
      "\n",
      "✅ All layers have matching requires_grad settings.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Phase 1 모델 로드 (내가 구현한 모델)\n",
    "phase1_model_path = \"/mnt/Hover-Net/Hover-Net_Custom/checkpoints/phase1_model.tar\"\n",
    "phase1_model = load_model(phase1_model_path, model_class, device=\"cuda\")\n",
    "\n",
    "# ✅ Phase 2 모델 로드 (원본 코드 모델)\n",
    "phase2_model_path = \"/mnt/Hover-Net/Hover-Net_original/logs/05/net_epoch=1.tar\"\n",
    "phase2_model = load_original_model(phase2_model_path, model_class, device=\"cuda\")\n",
    "\n",
    "# ✅ 모델 비교 실행\n",
    "compare_models(phase1_model, phase2_model, model1_name=\"My Model (Phase 1)\", model2_name=\"Original Model (Phase 2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 Key 목록:\n",
      "desc\n",
      "optimizer\n",
      "lr_scheduler\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# .tar 파일 로드\n",
    "checkpoint_path = \"/mnt/Hover-Net/Hover-Net_original/logs/05_phase1/net_epoch=1.tar\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "# 저장된 key 확인\n",
    "print(\"저장된 Key 목록:\")\n",
    "for key in checkpoint.keys():\n",
    "    print(key)\n",
    "\n",
    "# 모델 가중치 확인 (모델 state_dict만 확인하고 싶다면)\n",
    "if 'desc' in checkpoint:\n",
    "    print(\"\\n모델 파라미터 목록:\")\n",
    "    for param_tensor in checkpoint['model_state_dict']:\n",
    "        print(param_tensor, \"\\t\", checkpoint['model_state_dict'][param_tensor].size())\n",
    "\n",
    "# 옵티마이저 확인\n",
    "if 'optimizer_state_dict' in checkpoint:\n",
    "    print(\"\\n옵티마이저 상태 확인 성공\")\n",
    "\n",
    "# 학습률 스케줄러 확인\n",
    "if 'scheduler_state_dict' in checkpoint:\n",
    "    print(\"\\n스케줄러 상태 확인 성공\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Model Loaded Successfully\n",
      "저장된 Key 목록:\n",
      "epoch\n",
      "model_state_dict\n",
      "optimizer_state_dict\n",
      "scheduler_state_dict\n",
      "loss\n"
     ]
    }
   ],
   "source": [
    "phase1_model_path = \"/mnt/Hover-Net/Hover-Net_Custom/checkpoints/phase1_model.tar\"\n",
    "custom_model = torch.load(phase1_model_path, map_location='cpu')\n",
    "print(\"Custom Model Loaded Successfully\")\n",
    "print(\"저장된 Key 목록:\")\n",
    "for key in custom_model.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Keys in Original but not in Custom:\n",
      "{'module.d3.units.2.conv1/bn.weight', 'module.decoder.tp.u2.dense.units.0.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.0.conv2.weight', 'module.d0.units.0.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.conva.weight', 'module.decoder.tp.u3.dense.units.3.preact_bna/bn.running_var', 'module.d0.units.0.conv2/bn.num_batches_tracked', 'module.d1.units.3.conv1/bn.bias', 'module.d2.units.1.conv2/bn.running_mean', 'module.decoder.hv.u2.dense.blk_bna.bn.bias', 'module.d2.units.5.preact/bn.bias', 'module.decoder.np.u3.dense.units.7.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.5.preact_bna/bn.bias', 'module.decoder.tp.u2.dense.units.2.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.tp.u3.dense.units.2.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.5.conv1/bn.weight', 'module.decoder.hv.u1.conva.weight', 'module.decoder.hv.u3.dense.units.2.conv1.weight', 'module.d1.units.2.preact/bn.bias', 'module.d1.units.2.conv1/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.0.preact_bna/bn.bias', 'module.d0.units.2.conv1/bn.bias', 'module.decoder.np.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.2.preact_bna/bn.weight', 'module.d0.units.1.conv2/bn.running_var', 'module.decoder.np.u2.dense.units.0.conv1.weight', 'module.decoder.tp.u2.dense.units.1.conv1/bn.bias', 'module.decoder.np.u2.dense.blk_bna.bn.weight', 'module.decoder.tp.u2.dense.units.3.conv1/bn.running_mean', 'module.d3.units.0.conv2/bn.num_batches_tracked', 'module.d0.units.1.preact/bn.bias', 'module.d2.units.5.preact/bn.running_var', 'module.decoder.np.u3.dense.units.2.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.7.conv2.weight', 'module.decoder.hv.u3.dense.units.7.preact_bna/bn.bias', 'module.decoder.hv.u2.dense.units.3.preact_bna/bn.bias', 'module.d1.blk_bna.bn.num_batches_tracked', 'module.d1.units.2.conv2/bn.weight', 'module.decoder.np.u3.dense.units.5.conv1/bn.weight', 'module.decoder.tp.u2.dense.units.3.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.1.conv1/bn.running_var', 'module.decoder.tp.u2.dense.blk_bna.bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.3.conv1/bn.weight', 'module.decoder.tp.u3.dense.units.3.preact_bna/bn.weight', 'module.decoder.np.u3.dense.units.4.conv1/bn.bias', 'module.decoder.np.u2.dense.units.3.conv1/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.3.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.1.preact_bna/bn.weight', 'module.decoder.np.u3.dense.units.7.preact_bna/bn.weight', 'module.decoder.np.u2.dense.units.1.preact_bna/bn.running_var', 'module.d3.units.1.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.2.preact_bna/bn.running_var', 'module.decoder.tp.u3.dense.units.0.conv1/bn.bias', 'module.d2.units.0.conv3.weight', 'module.decoder.np.u3.dense.units.7.conv1/bn.weight', 'module.decoder.tp.u2.conva.weight', 'module.decoder.np.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.1.conv1/bn.running_var', 'module.decoder.np.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.0.conv1/bn.num_batches_tracked', 'module.d1.units.3.preact/bn.bias', 'module.decoder.np.u2.dense.units.3.conv1.weight', 'module.decoder.np.u2.dense.units.0.conv1/bn.running_mean', 'module.d1.units.3.conv3.weight', 'module.decoder.np.u3.dense.units.0.conv1/bn.running_mean', 'module.d2.units.2.preact/bn.running_mean', 'module.decoder.np.u3.dense.units.6.preact_bna/bn.running_mean', 'module.decoder.tp.u2.dense.units.1.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.0.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.6.conv1/bn.running_mean', 'module.d0.blk_bna.bn.weight', 'module.d0.units.0.conv2/bn.running_var', 'module.decoder.np.u3.dense.blk_bna.bn.weight', 'module.decoder.hv.u3.dense.units.0.preact_bna/bn.running_var', 'module.decoder.tp.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.d2.units.4.preact/bn.bias', 'module.d1.units.1.preact/bn.weight', 'module.decoder.np.u2.dense.units.0.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.7.conv1/bn.num_batches_tracked', 'module.d3.units.0.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'module.conv0./.weight', 'module.d2.units.1.conv2.weight', 'module.decoder.tp.u3.dense.units.7.conv1/bn.weight', 'module.d2.units.4.conv1/bn.running_mean', 'module.d2.units.1.conv2/bn.running_var', 'module.decoder.tp.u3.dense.units.5.conv1/bn.bias', 'module.d0.units.0.conv1/bn.running_var', 'module.decoder.np.u3.dense.units.6.conv2.weight', 'module.d1.units.2.preact/bn.running_var', 'module.decoder.tp.u2.dense.units.1.preact_bna/bn.bias', 'module.d1.units.3.conv2.weight', 'module.decoder.np.u2.dense.units.3.preact_bna/bn.bias', 'module.decoder.tp.u3.dense.units.4.preact_bna/bn.weight', 'module.d2.units.4.conv2/bn.running_var', 'module.decoder.hv.u2.dense.units.1.conv1/bn.bias', 'module.decoder.np.u3.dense.units.6.conv1.weight', 'module.decoder.hv.u3.dense.units.5.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.conv1.weight', 'module.decoder.np.u3.dense.blk_bna.bn.running_mean', 'module.decoder.hv.u2.dense.units.1.conv1/bn.running_mean', 'module.d3.units.2.preact/bn.bias', 'module.decoder.hv.u2.dense.units.1.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.5.conv1.weight', 'module.d0.units.1.conv2/bn.bias', 'module.decoder.hv.u3.dense.units.0.conv1.weight', 'module.d3.units.1.conv2/bn.weight', 'module.decoder.tp.u3.dense.units.4.conv1/bn.num_batches_tracked', 'module.d2.units.2.conv1/bn.running_var', 'module.decoder.hv.u3.dense.units.5.conv1/bn.bias', 'module.d2.units.4.preact/bn.running_mean', 'module.d3.units.2.conv2/bn.bias', 'module.decoder.hv.u0.bn.running_var', 'module.decoder.tp.u2.dense.units.2.conv1.weight', 'module.d2.units.4.conv1/bn.running_var', 'module.decoder.np.u3.dense.units.3.conv2.weight', 'module.d3.units.1.preact/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.1.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.blk_bna.bn.running_mean', 'module.decoder.tp.u2.dense.units.0.conv1/bn.weight', 'module.d2.units.5.conv2.weight', 'module.decoder.tp.u3.dense.units.4.conv1.weight', 'module.decoder.tp.u2.dense.units.2.conv1/bn.bias', 'module.decoder.hv.u3.dense.units.4.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.7.conv1/bn.running_var', 'module.decoder.np.u2.dense.blk_bna.bn.running_var', 'module.decoder.hv.u2.dense.units.1.conv2.weight', 'module.decoder.np.u3.dense.units.3.preact_bna/bn.running_var', 'module.d3.blk_bna.bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.4.conv1/bn.running_var', 'module.d0.units.2.conv3.weight', 'module.decoder.hv.u0.bn.num_batches_tracked', 'module.d3.units.0.conv1.weight', 'module.d2.units.4.conv2/bn.bias', 'module.d3.units.0.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.3.conv2.weight', 'module.decoder.tp.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'module.d2.units.3.preact/bn.weight', 'module.decoder.tp.u3.dense.units.0.conv1.weight', 'module.decoder.hv.u3.dense.units.7.conv1/bn.weight', 'module.d3.units.1.preact/bn.running_var', 'module.d2.units.1.conv1/bn.num_batches_tracked', 'module.d1.units.3.preact/bn.weight', 'module.decoder.np.u3.dense.units.4.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.7.conv2.weight', 'module.decoder.np.u3.dense.units.3.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.4.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.6.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.units.6.conv1/bn.weight', 'module.decoder.np.u3.dense.units.6.preact_bna/bn.weight', 'module.d0.units.1.conv1/bn.running_var', 'module.d3.units.2.preact/bn.num_batches_tracked', 'module.decoder.hv.u2.dense.units.1.preact_bna/bn.weight', 'module.d2.units.4.preact/bn.running_var', 'module.d2.units.3.conv1.weight', 'module.d1.units.2.conv1/bn.weight', 'module.decoder.np.u3.dense.units.0.conv1.weight', 'module.decoder.hv.u3.dense.units.4.conv2.weight', 'module.decoder.np.u0.conv.bias', 'module.d2.units.5.conv1/bn.weight', 'module.d3.units.2.conv2/bn.running_var', 'module.d3.units.1.conv1/bn.running_mean', 'module.decoder.tp.u0.bn.running_mean', 'module.decoder.np.u3.dense.units.1.conv2.weight', 'module.d0.units.2.conv2.weight', 'module.decoder.hv.u2.dense.units.2.conv1/bn.bias', 'module.decoder.hv.u2.dense.units.3.preact_bna/bn.running_mean', 'module.decoder.tp.u3.dense.units.1.preact_bna/bn.running_var', 'module.decoder.tp.u3.dense.blk_bna.bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.5.conv1/bn.bias', 'module.decoder.hv.u3.dense.blk_bna.bn.bias', 'module.decoder.tp.u3.convf.weight', 'module.d3.units.1.conv1.weight', 'module.d1.units.1.conv1/bn.bias', 'module.d0.units.2.conv1/bn.running_mean', 'module.d2.units.3.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.units.3.conv2.weight', 'module.decoder.tp.u0.conv.bias', 'module.d1.units.2.conv2/bn.running_var', 'module.d2.units.0.conv2/bn.running_mean', 'module.decoder.tp.u2.dense.units.3.preact_bna/bn.running_var', 'module.decoder.hv.u2.dense.units.0.conv1/bn.running_mean', 'module.decoder.np.u2.dense.units.3.preact_bna/bn.running_mean', 'module.d2.units.4.preact/bn.num_batches_tracked', 'module.decoder.tp.u1.conva.weight', 'module.d0.units.0.conv1/bn.bias', 'module.d0.units.2.conv1.weight', 'module.decoder.tp.u3.dense.units.0.conv1/bn.running_var', 'module.decoder.np.u3.dense.units.3.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.units.0.preact_bna/bn.weight', 'module.decoder.hv.u2.dense.units.1.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.2.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.7.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.4.conv2.weight', 'module.decoder.np.u3.dense.units.7.preact_bna/bn.bias', 'module.decoder.hv.u3.dense.units.3.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.units.0.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.units.3.conv1.weight', 'module.decoder.np.u3.dense.units.0.preact_bna/bn.running_mean', 'module.decoder.tp.u2.dense.units.3.conv1/bn.running_var', 'module.decoder.np.u3.dense.blk_bna.bn.running_var', 'module.decoder.tp.u2.dense.units.0.conv2.weight', 'module.decoder.np.u2.dense.units.2.preact_bna/bn.running_var', 'module.decoder.tp.u3.dense.units.6.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.0.conv2.weight', 'module.decoder.tp.u3.dense.units.6.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.7.conv1.weight', 'module.decoder.tp.u3.dense.units.3.conv1/bn.num_batches_tracked', 'module.d2.units.0.conv1/bn.bias', 'module.decoder.tp.u2.dense.units.2.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.0.conv1/bn.bias', 'module.d1.units.1.conv2/bn.num_batches_tracked', 'module.d2.units.0.conv2/bn.bias', 'module.d2.units.1.conv1/bn.weight', 'module.decoder.np.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.5.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.decoder.hv.u2.conva.weight', 'module.decoder.np.u3.dense.units.1.preact_bna/bn.running_mean', 'module.d3.units.0.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.blk_bna.bn.bias', 'module.d2.units.2.conv1.weight', 'module.decoder.tp.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.1.preact_bna/bn.weight', 'module.d2.units.3.conv2.weight', 'module.decoder.hv.u3.dense.units.6.preact_bna/bn.bias', 'module.decoder.tp.u2.dense.units.0.preact_bna/bn.weight', 'module.d0.units.0.conv2/bn.bias', 'module.d1.units.1.preact/bn.running_mean', 'module.decoder.hv.u2.dense.units.3.preact_bna/bn.weight', 'module.d0.units.1.conv2/bn.running_mean', 'module.decoder.tp.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.1.conv1/bn.bias', 'module.decoder.np.u2.dense.units.0.conv1/bn.bias', 'module.decoder.hv.u2.convf.weight', 'module.d1.units.0.conv1/bn.running_mean', 'module.decoder.tp.u3.dense.units.2.conv1/bn.running_mean', 'module.d0.units.1.conv1/bn.running_mean', 'module.decoder.np.u3.dense.units.4.conv1.weight', 'module.d2.units.5.conv1/bn.num_batches_tracked', 'module.decoder.np.u0.bn.bias', 'module.d1.units.0.conv1/bn.running_var', 'module.d2.units.2.conv2/bn.running_var', 'module.d0.units.1.conv3.weight', 'module.decoder.np.u3.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.np.u2.dense.units.0.preact_bna/bn.weight', 'module.decoder.hv.u2.dense.blk_bna.bn.weight', 'module.decoder.np.u3.dense.units.2.preact_bna/bn.bias', 'module.d1.units.0.conv3.weight', 'module.d1.units.1.conv3.weight', 'module.decoder.tp.u3.dense.units.5.conv2.weight', 'module.decoder.tp.u3.dense.units.1.conv2.weight', 'module.decoder.hv.u3.dense.units.2.preact_bna/bn.running_var', 'module.decoder.tp.u2.dense.units.3.preact_bna/bn.bias', 'module.decoder.tp.u3.dense.units.3.preact_bna/bn.bias', 'module.d1.units.0.conv2/bn.weight', 'module.decoder.hv.u3.dense.units.3.conv2.weight', 'module.decoder.tp.u3.dense.units.0.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.3.conv1.weight', 'module.decoder.tp.u0.bn.running_var', 'module.decoder.np.u3.dense.units.7.conv1/bn.running_var', 'module.d1.units.2.conv2.weight', 'module.decoder.tp.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'module.d2.units.3.preact/bn.running_var', 'module.d0.blk_bna.bn.running_var', 'module.d0.blk_bna.bn.running_mean', 'module.d2.units.5.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.1.conv1/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.2.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.4.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.1.preact_bna/bn.bias', 'module.decoder.hv.u0.bn.weight', 'module.decoder.tp.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.5.preact_bna/bn.weight', 'module.d2.shortcut.weight', 'module.d1.units.2.conv2/bn.running_mean', 'module.decoder.tp.u2.dense.units.1.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.0.preact_bna/bn.running_mean', 'module.decoder.np.u2.dense.units.3.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.2.preact_bna/bn.weight', 'module.d2.units.5.conv2/bn.running_mean', 'module.decoder.np.u2.dense.units.3.conv2.weight', 'module.decoder.tp.u2.dense.units.0.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.units.1.preact_bna/bn.running_var', 'module.d1.units.1.preact/bn.running_var', 'module.d2.units.4.conv2/bn.running_mean', 'module.decoder.tp.u3.dense.units.3.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.blk_bna.bn.weight', 'module.d0.units.2.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.4.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.3.conv1/bn.weight', 'module.d2.units.4.conv2/bn.num_batches_tracked', 'module.d3.units.1.conv2.weight', 'module.d1.units.3.conv2/bn.running_mean', 'module.d0.units.2.conv2/bn.weight', 'module.d3.units.2.conv1/bn.num_batches_tracked', 'module.d2.units.3.conv2/bn.weight', 'module.d2.units.2.conv1/bn.running_mean', 'module.decoder.np.u3.dense.units.6.preact_bna/bn.running_var', 'module.d2.units.1.conv1/bn.running_mean', 'module.decoder.np.u2.dense.blk_bna.bn.bias', 'module.decoder.hv.u3.dense.units.5.conv2.weight', 'module.d0.blk_bna.bn.bias', 'module.d3.units.0.conv2/bn.running_var', 'module.decoder.tp.u3.dense.units.5.conv1.weight', 'module.decoder.np.u3.dense.units.5.conv1/bn.running_mean', 'module.d0.blk_bna.bn.num_batches_tracked', 'module.d2.blk_bna.bn.weight', 'module.d1.units.3.conv1/bn.running_mean', 'module.d2.blk_bna.bn.running_var', 'module.decoder.np.u3.dense.units.5.conv1/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.d1.units.3.preact/bn.running_mean', 'module.d3.shortcut.weight', 'module.decoder.hv.u2.dense.units.3.preact_bna/bn.running_var', 'module.decoder.tp.u3.dense.units.1.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.7.conv1/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.1.conv1/bn.running_mean', 'module.decoder.np.u3.dense.units.5.preact_bna/bn.bias', 'module.decoder.hv.u3.dense.units.0.conv1/bn.running_var', 'module.decoder.hv.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'module.d1.units.2.conv1/bn.bias', 'module.decoder.hv.u3.dense.units.6.conv1/bn.bias', 'module.decoder.np.u3.dense.units.1.conv1.weight', 'module.decoder.np.u3.dense.units.1.preact_bna/bn.bias', 'module.decoder.hv.u2.dense.units.2.conv1/bn.running_var', 'module.d2.units.5.preact/bn.weight', 'module.d0.units.2.conv1/bn.running_var', 'module.decoder.np.u2.dense.units.2.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.0.conv1/bn.bias', 'module.d1.units.1.conv1/bn.weight', 'module.d0.units.2.preact/bn.running_mean', 'module.decoder.hv.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.4.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.4.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.0.conv1/bn.running_mean', 'module.d3.units.1.preact/bn.running_mean', 'module.d2.units.2.preact/bn.weight', 'module.decoder.np.u3.dense.units.0.conv1/bn.weight', 'module.decoder.tp.u3.dense.units.7.preact_bna/bn.running_var', 'module.d1.units.1.conv1.weight', 'module.d3.units.0.conv2/bn.running_mean', 'module.decoder.np.u3.dense.units.2.conv1/bn.running_var', 'module.decoder.tp.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.1.conv1/bn.running_mean', 'module.decoder.np.u3.dense.units.6.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.0.conv2.weight', 'module.d3.units.2.conv3.weight', 'module.decoder.hv.u2.dense.units.1.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.3.conv1.weight', 'module.decoder.np.u2.dense.units.3.conv1/bn.running_var', 'module.decoder.hv.u3.dense.units.4.preact_bna/bn.running_var', 'module.decoder.np.u0.bn.running_var', 'module.d2.units.0.conv1/bn.running_var', 'module.decoder.hv.u3.dense.units.4.preact_bna/bn.running_mean', 'module.decoder.hv.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.d1.units.2.preact/bn.running_mean', 'module.d2.units.5.conv1/bn.bias', 'module.d3.units.2.preact/bn.running_var', 'module.decoder.tp.u3.dense.units.1.conv1/bn.weight', 'module.decoder.tp.u3.dense.units.5.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.5.conv1/bn.running_var', 'module.d2.units.0.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.2.preact_bna/bn.weight', 'module.decoder.hv.u2.dense.units.2.preact_bna/bn.weight', 'module.decoder.np.u2.dense.units.2.conv1/bn.num_batches_tracked', 'module.decoder.np.u0.bn.running_mean', 'module.d0.units.1.preact/bn.num_batches_tracked', 'module.d3.blk_bna.bn.bias', 'module.decoder.hv.u3.dense.blk_bna.bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.6.preact_bna/bn.weight', 'module.d0.units.2.conv2/bn.bias', 'module.d1.units.0.conv2/bn.running_var', 'module.d2.units.2.conv3.weight', 'module.decoder.np.u3.dense.units.0.preact_bna/bn.weight', 'module.d3.units.0.conv2/bn.weight', 'module.d2.units.4.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.7.preact_bna/bn.weight', 'module.d3.units.1.conv1/bn.num_batches_tracked', 'module.d0.shortcut.weight', 'module.decoder.hv.u2.dense.units.2.conv1/bn.num_batches_tracked', 'module.d2.units.2.conv1/bn.weight', 'module.decoder.np.u2.dense.units.2.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.7.preact_bna/bn.running_mean', 'module.decoder.tp.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.7.preact_bna/bn.bias', 'module.d1.units.0.conv2/bn.bias', 'module.d2.units.4.conv2/bn.weight', 'module.decoder.np.u3.dense.units.1.conv1/bn.running_var', 'module.d1.units.3.preact/bn.running_var', 'module.d1.units.0.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.6.conv1/bn.bias', 'module.decoder.np.u0.conv.weight', 'module.decoder.hv.u3.dense.units.3.preact_bna/bn.running_mean', 'module.d2.units.3.preact/bn.bias', 'module.decoder.np.u2.dense.units.1.preact_bna/bn.weight', 'module.decoder.tp.u3.dense.units.6.preact_bna/bn.running_var', 'module.d2.units.2.conv2.weight', 'module.decoder.hv.u0.bn.running_mean', 'module.d2.units.3.conv2/bn.bias', 'module.decoder.tp.u3.dense.units.7.conv1/bn.bias', 'module.decoder.np.u3.dense.units.1.preact_bna/bn.weight', 'module.decoder.tp.u0.bn.num_batches_tracked', 'module.d0.units.2.conv2/bn.running_var', 'module.d3.units.2.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.6.conv1/bn.running_mean', 'module.decoder.np.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.d2.units.4.conv1.weight', 'module.decoder.hv.u3.dense.units.5.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.1.preact_bna/bn.running_mean', 'module.d1.units.3.conv2/bn.running_var', 'module.decoder.hv.u3.dense.units.4.conv1/bn.running_var', 'module.decoder.hv.u3.dense.units.7.preact_bna/bn.running_mean', 'module.d2.units.3.conv2/bn.running_var', 'module.decoder.np.u3.dense.units.4.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.0.conv1/bn.bias', 'module.decoder.tp.u2.dense.blk_bna.bn.bias', 'module.d2.units.4.conv1/bn.weight', 'module.d1.blk_bna.bn.bias', 'module.decoder.np.u3.dense.units.4.preact_bna/bn.weight', 'module.decoder.np.u3.dense.units.6.conv1/bn.running_var', 'module.decoder.np.u2.dense.units.2.conv2.weight', 'module.decoder.np.u3.dense.units.3.conv1/bn.running_var', 'module.d0.units.1.preact/bn.running_mean', 'module.decoder.hv.u3.dense.units.6.preact_bna/bn.running_mean', 'module.decoder.tp.u3.conva.weight', 'module.decoder.hv.u3.dense.units.1.conv1.weight', 'module.d2.units.3.conv1/bn.bias', 'module.d0.units.1.conv1/bn.weight', 'module.d0.units.1.conv2.weight', 'module.d1.units.3.conv1/bn.running_var', 'module.d3.units.0.conv2.weight', 'module.decoder.tp.u3.dense.blk_bna.bn.weight', 'module.decoder.tp.u3.dense.blk_bna.bn.running_mean', 'module.d3.blk_bna.bn.running_var', 'module.decoder.tp.u3.dense.units.5.preact_bna/bn.running_mean', 'module.decoder.hv.u2.dense.blk_bna.bn.num_batches_tracked', 'module.d2.units.0.conv1.weight', 'module.d3.units.1.conv1/bn.bias', 'module.d3.units.2.conv2.weight', 'module.decoder.tp.u2.dense.units.0.conv1/bn.num_batches_tracked', 'module.d2.units.2.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.0.conv1/bn.weight', 'module.d2.units.4.preact/bn.weight', 'module.decoder.tp.u3.dense.units.6.preact_bna/bn.running_mean', 'module.d2.blk_bna.bn.num_batches_tracked', 'module.d2.units.1.conv2/bn.weight', 'module.decoder.hv.u3.dense.units.1.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.2.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.d2.units.1.preact/bn.weight', 'module.decoder.hv.u3.dense.units.5.conv1.weight', 'module.decoder.np.u3.dense.units.3.preact_bna/bn.running_mean', 'module.decoder.tp.u3.dense.units.6.conv1/bn.running_var', 'module.d1.units.1.conv2/bn.weight', 'module.decoder.tp.u3.dense.units.2.conv1/bn.bias', 'module.d1.units.3.preact/bn.num_batches_tracked', 'module.d0.units.2.preact/bn.running_var', 'module.d1.units.2.conv3.weight', 'module.d1.units.3.conv1.weight', 'module.d2.units.3.conv3.weight', 'module.decoder.np.u3.dense.units.2.conv1/bn.bias', 'module.d2.blk_bna.bn.running_mean', 'module.d2.units.5.preact/bn.running_mean', 'module.decoder.np.u3.convf.weight', 'module.decoder.hv.u0.conv.bias', 'module.decoder.np.u3.dense.units.5.preact_bna/bn.running_mean', 'module.decoder.hv.u2.dense.units.2.conv2.weight', 'module.d2.units.1.preact/bn.running_var', 'module.decoder.np.u3.dense.units.7.conv1.weight', 'module.decoder.np.u3.conva.weight', 'module.decoder.tp.u3.dense.units.3.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.7.conv1/bn.running_var', 'module.decoder.tp.u2.dense.units.1.conv1.weight', 'module.decoder.tp.u2.dense.units.3.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.1.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.5.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.units.4.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.0.conv1.weight', 'module.d0.units.0.conv2/bn.weight', 'module.decoder.hv.u3.dense.units.3.preact_bna/bn.weight', 'module.decoder.hv.u3.dense.units.1.conv1/bn.running_var', 'module.d1.units.1.preact/bn.bias', 'module.d2.units.2.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.4.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.blk_bna.bn.running_var', 'module.decoder.np.u3.dense.units.4.preact_bna/bn.bias', 'module.decoder.hv.u3.dense.units.2.preact_bna/bn.bias', 'module.decoder.np.u2.dense.units.2.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.3.conv1/bn.bias', 'module.decoder.np.u3.dense.units.4.conv2.weight', 'module.d1.units.3.conv2/bn.bias', 'module.decoder.hv.u3.dense.units.4.conv1/bn.bias', 'module.d1.units.1.conv2.weight', 'module.decoder.tp.u3.dense.units.2.preact_bna/bn.running_var', 'module.d3.blk_bna.bn.weight', 'module.d2.units.2.conv2/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.0.conv1/bn.running_var', 'module.d2.units.4.conv1/bn.bias', 'module.decoder.tp.u2.dense.units.2.conv2.weight', 'module.d1.units.1.conv1/bn.running_var', 'module.d2.units.1.conv2/bn.bias', 'module.decoder.np.u3.dense.units.2.conv1/bn.weight', 'module.decoder.np.u3.dense.units.3.conv1/bn.weight', 'module.d2.units.3.preact/bn.running_mean', 'module.decoder.hv.u3.convf.weight', 'module.d2.units.3.preact/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.5.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.blk_bna.bn.running_var', 'module.d3.units.1.conv2/bn.bias', 'module.decoder.np.u3.dense.units.7.preact_bna/bn.running_mean', 'module.d2.units.4.conv3.weight', 'module.decoder.hv.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.1.conv2.weight', 'module.d0.units.2.conv1/bn.weight', 'module.decoder.hv.u2.dense.units.1.preact_bna/bn.running_mean', 'module.conv0.bn.running_var', 'module.d1.units.1.conv2/bn.running_var', 'module.decoder.hv.u2.dense.units.0.conv1/bn.num_batches_tracked', 'module.d0.units.0.conv2.weight', 'module.conv0.bn.num_batches_tracked', 'module.decoder.tp.u0.conv.weight', 'module.d0.units.2.preact/bn.weight', 'module.decoder.tp.u2.dense.units.0.conv1/bn.running_mean', 'module.d2.units.3.conv2/bn.running_mean', 'module.decoder.np.u3.dense.units.1.conv1/bn.weight', 'module.decoder.np.u3.dense.units.3.conv1/bn.bias', 'module.conv0.bn.bias', 'module.d0.units.1.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.6.conv1/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.blk_bna.bn.running_mean', 'module.decoder.tp.u2.dense.units.1.preact_bna/bn.weight', 'module.decoder.np.u3.dense.units.4.preact_bna/bn.running_var', 'module.d2.units.0.conv1/bn.num_batches_tracked', 'module.d0.units.1.conv1/bn.bias', 'module.d0.units.1.conv2/bn.weight', 'module.d3.units.0.conv1/bn.running_mean', 'module.decoder.tp.u3.dense.units.4.preact_bna/bn.running_var', 'module.d3.units.2.conv2/bn.running_mean', 'module.decoder.np.u3.dense.units.6.conv1/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.3.conv1/bn.num_batches_tracked', 'module.d2.units.4.conv2.weight', 'module.d2.units.0.conv2/bn.running_var', 'module.d3.units.1.conv2/bn.running_mean', 'module.decoder.tp.u3.dense.units.1.preact_bna/bn.bias', 'module.decoder.np.u2.dense.units.0.conv2.weight', 'module.decoder.hv.u2.dense.units.3.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.3.conv1/bn.weight', 'module.decoder.np.u3.dense.units.3.preact_bna/bn.bias', 'module.decoder.hv.u2.dense.units.1.conv1/bn.num_batches_tracked', 'module.d3.units.1.conv2/bn.running_var', 'module.decoder.hv.u3.dense.units.0.conv1/bn.weight', 'module.decoder.np.u2.dense.units.3.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.2.conv1/bn.weight', 'module.d2.units.2.preact/bn.num_batches_tracked', 'module.decoder.tp.u2.convf.weight', 'module.d2.units.0.conv1/bn.weight', 'module.d1.units.3.conv2/bn.weight', 'module.d2.units.1.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.2.conv1/bn.running_var', 'module.d0.units.2.conv2/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.2.conv1/bn.running_var', 'module.d2.units.1.preact/bn.bias', 'module.decoder.np.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.conv0.bn.weight', 'module.decoder.np.u3.dense.units.4.conv1/bn.running_mean', 'module.decoder.hv.u3.dense.units.6.conv1/bn.running_var', 'module.d1.units.2.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.1.conv1/bn.bias', 'module.decoder.np.u2.dense.units.1.conv1.weight', 'module.decoder.np.u2.dense.units.1.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.5.conv2.weight', 'module.decoder.tp.u2.dense.units.0.preact_bna/bn.bias', 'module.decoder.hv.u2.dense.units.0.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.2.conv1.weight', 'module.d2.units.5.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.units.2.preact_bna/bn.running_var', 'module.decoder.hv.u2.dense.units.0.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.3.preact_bna/bn.bias', 'module.decoder.hv.u2.dense.units.0.conv1/bn.weight', 'module.d2.units.5.conv2/bn.bias', 'module.d3.units.2.conv1/bn.bias', 'module.d1.units.2.conv2/bn.bias', 'module.decoder.hv.u3.dense.units.0.preact_bna/bn.bias', 'module.decoder.np.u2.dense.blk_bna.bn.running_mean', 'module.decoder.np.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.d1.units.1.conv1/bn.running_mean', 'module.d3.units.1.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.6.conv1.weight', 'module.decoder.np.u2.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.np.u3.dense.units.0.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.conv1/bn.running_mean', 'module.d3.units.0.conv1/bn.running_var', 'module.d2.units.1.conv1/bn.bias', 'module.d3.units.1.preact/bn.bias', 'module.decoder.np.u2.dense.units.2.conv1/bn.running_mean', 'module.d3.blk_bna.bn.running_mean', 'module.decoder.hv.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.1.conv1/bn.weight', 'module.d1.units.0.conv1/bn.bias', 'module.decoder.tp.u2.dense.units.0.preact_bna/bn.running_mean', 'module.decoder.tp.u3.dense.units.6.conv1.weight', 'module.d1.units.3.conv1/bn.num_batches_tracked', 'module.d2.units.5.conv1/bn.running_var', 'module.d3.units.1.conv1/bn.running_var', 'module.d1.blk_bna.bn.running_var', 'module.d1.units.0.conv1.weight', 'module.decoder.tp.u2.dense.units.2.preact_bna/bn.bias', 'module.decoder.np.u2.convf.weight', 'module.d2.units.5.conv2/bn.weight', 'module.d1.units.3.conv2/bn.num_batches_tracked', 'module.d0.units.1.conv2/bn.num_batches_tracked', 'module.decoder.np.u3.dense.units.1.preact_bna/bn.running_var', 'module.decoder.np.u2.dense.units.1.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.conv2.weight', 'module.decoder.hv.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'module.d1.units.0.conv2/bn.num_batches_tracked', 'module.d2.units.3.conv2/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.1.conv2.weight', 'module.decoder.tp.u3.dense.units.2.conv1.weight', 'module.d0.units.0.conv2/bn.running_mean', 'module.decoder.np.u2.dense.units.0.preact_bna/bn.running_mean', 'module.d0.units.0.conv1/bn.weight', 'module.decoder.tp.u3.dense.units.0.preact_bna/bn.bias', 'module.d2.units.2.conv2/bn.bias', 'module.decoder.tp.u3.dense.blk_bna.bn.running_var', 'module.decoder.tp.u3.dense.units.2.conv1/bn.weight', 'module.d2.units.1.conv1.weight', 'module.decoder.hv.u3.dense.units.7.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.blk_bna.bn.running_mean', 'module.d2.units.1.preact/bn.running_mean', 'module.decoder.tp.u3.dense.units.3.conv2.weight', 'module.d2.units.2.preact/bn.running_var', 'module.decoder.np.u3.dense.units.5.preact_bna/bn.running_var', 'module.decoder.hv.u3.dense.units.4.conv1.weight', 'module.decoder.hv.u3.dense.units.5.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.5.conv1/bn.running_mean', 'module.decoder.tp.u3.dense.units.2.preact_bna/bn.weight', 'module.decoder.hv.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.0.conv1.weight', 'module.d1.units.2.conv1/bn.running_mean', 'module.d1.blk_bna.bn.weight', 'module.d2.units.5.conv2/bn.running_var', 'module.decoder.tp.u3.dense.units.3.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.1.preact_bna/bn.running_mean', 'module.d2.units.1.preact/bn.num_batches_tracked', 'module.d0.units.0.conv1.weight', 'module.d2.units.5.conv1.weight', 'module.d3.units.1.preact/bn.weight', 'module.decoder.np.u3.dense.blk_bna.bn.bias', 'module.decoder.hv.u3.dense.units.2.conv1/bn.bias', 'module.decoder.np.u1.conva.weight', 'module.decoder.hv.u3.dense.units.0.preact_bna/bn.weight', 'module.decoder.hv.u3.dense.units.4.preact_bna/bn.bias', 'module.d2.units.1.conv3.weight', 'module.decoder.np.u2.dense.units.1.conv1/bn.bias', 'module.d2.units.5.preact/bn.num_batches_tracked', 'module.d2.units.0.conv1/bn.running_mean', 'module.decoder.tp.u3.dense.units.2.conv1/bn.num_batches_tracked', 'module.d0.units.1.preact/bn.weight', 'module.d1.units.0.conv1/bn.weight', 'module.d2.blk_bna.bn.bias', 'module.decoder.np.u3.dense.units.2.conv2.weight', 'module.decoder.np.u2.dense.units.0.conv1/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.1.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.3.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.units.0.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.3.conv1/bn.bias', 'module.d0.units.2.preact/bn.bias', 'module.decoder.np.u3.dense.units.0.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.4.preact_bna/bn.bias', 'module.d1.units.1.preact/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'module.d1.units.1.conv2/bn.running_mean', 'module.decoder.np.u2.dense.units.3.conv1/bn.bias', 'module.decoder.tp.u3.dense.units.1.conv1.weight', 'module.decoder.hv.u3.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.hv.u3.dense.units.6.conv2.weight', 'module.decoder.tp.u3.dense.units.6.conv2.weight', 'module.decoder.hv.u2.dense.units.0.preact_bna/bn.bias', 'module.d3.units.0.conv2/bn.bias', 'module.d2.units.2.preact/bn.bias', 'module.d2.units.2.conv2/bn.running_mean', 'module.decoder.np.u3.dense.units.6.conv1/bn.weight', 'module.d3.units.1.conv3.weight', 'module.decoder.hv.u3.dense.units.3.conv1/bn.bias', 'module.decoder.hv.u0.bn.bias', 'module.decoder.tp.u2.dense.units.0.conv1/bn.running_var', 'module.decoder.hv.u2.dense.units.3.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.2.preact_bna/bn.bias', 'module.decoder.np.u3.dense.units.7.preact_bna/bn.running_var', 'module.decoder.hv.u2.dense.units.3.conv1.weight', 'module.decoder.np.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.conv_bot.weight', 'module.decoder.tp.u3.dense.units.6.preact_bna/bn.bias', 'module.d2.units.3.conv1/bn.weight', 'module.decoder.tp.u3.dense.units.2.conv2.weight', 'module.decoder.hv.u3.dense.units.5.conv1/bn.running_mean', 'module.d3.units.2.conv2/bn.num_batches_tracked', 'module.d3.units.2.conv2/bn.weight', 'module.decoder.tp.u3.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.tp.u3.dense.units.5.preact_bna/bn.running_var', 'module.d2.units.3.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.conv1/bn.bias', 'module.decoder.np.u2.dense.blk_bna.bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.3.conv1.weight', 'module.d0.units.1.preact/bn.running_var', 'module.d1.shortcut.weight', 'module.d3.units.2.conv1/bn.running_mean', 'module.d1.units.0.conv2.weight', 'module.d1.units.0.conv2/bn.running_mean', 'module.d1.blk_bna.bn.running_mean', 'module.d3.units.2.conv1.weight', 'module.decoder.np.u3.dense.units.7.conv1/bn.bias', 'module.decoder.np.u0.bn.weight', 'module.decoder.hv.u3.dense.units.5.conv1/bn.weight', 'module.decoder.hv.u3.dense.units.2.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.7.conv1/bn.num_batches_tracked', 'module.decoder.hv.u2.dense.units.0.conv2.weight', 'module.d1.units.2.conv1.weight', 'module.decoder.np.u3.dense.units.2.conv1/bn.num_batches_tracked', 'module.d2.units.5.conv3.weight', 'module.d0.units.2.preact/bn.num_batches_tracked', 'module.d2.units.1.conv1/bn.running_var', 'module.d2.units.3.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.7.conv1/bn.running_mean', 'module.decoder.tp.u2.dense.units.1.conv1/bn.running_mean', 'module.d1.units.1.conv1/bn.num_batches_tracked', 'module.decoder.hv.u3.dense.units.6.conv1/bn.num_batches_tracked', 'module.d1.units.2.preact/bn.num_batches_tracked', 'module.decoder.hv.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'module.d1.units.3.conv1/bn.weight', 'module.d1.units.2.preact/bn.weight', 'module.d0.units.1.conv1.weight', 'module.decoder.hv.u3.dense.blk_bna.bn.weight', 'module.decoder.hv.u3.dense.units.3.conv1/bn.running_var', 'module.d0.units.0.conv3.weight', 'module.decoder.np.u2.dense.units.2.conv1/bn.running_var', 'module.decoder.tp.u2.dense.units.3.conv1/bn.weight', 'module.upsample2x.unpool_mat', 'module.decoder.np.u2.dense.units.1.conv1/bn.running_var', 'module.decoder.tp.u2.dense.units.3.conv1/bn.num_batches_tracked', 'module.decoder.tp.u2.dense.units.1.conv1/bn.num_batches_tracked', 'module.decoder.np.u2.dense.units.2.conv1.weight', 'module.decoder.hv.u2.dense.blk_bna.bn.running_var', 'module.d1.units.1.conv2/bn.bias', 'module.decoder.hv.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'module.decoder.hv.u2.dense.units.3.conv1/bn.running_mean', 'module.decoder.np.u2.conva.weight', 'module.decoder.hv.u0.conv.weight', 'module.decoder.hv.u2.dense.units.2.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.units.1.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.2.conv1/bn.running_mean', 'module.d3.units.2.preact/bn.running_mean', 'module.decoder.np.u3.dense.units.0.preact_bna/bn.running_var', 'module.decoder.np.u3.dense.units.5.conv1/bn.running_var', 'module.decoder.np.u3.dense.units.6.preact_bna/bn.bias', 'module.decoder.np.u2.dense.units.0.conv1/bn.weight', 'module.decoder.np.u2.dense.units.2.preact_bna/bn.weight', 'module.decoder.hv.u3.dense.units.2.conv2.weight', 'module.decoder.hv.u3.dense.units.6.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.units.2.conv1.weight', 'module.decoder.hv.u2.dense.units.1.conv1.weight', 'module.d2.units.0.conv2.weight', 'module.decoder.tp.u0.bn.weight', 'module.decoder.np.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.4.conv1/bn.bias', 'module.conv0.bn.running_mean', 'module.decoder.hv.u3.dense.units.0.conv1/bn.num_batches_tracked', 'module.d1.units.2.conv1/bn.running_var', 'module.decoder.tp.u3.dense.units.0.preact_bna/bn.running_mean', 'module.decoder.tp.u0.bn.bias', 'module.decoder.hv.u3.dense.units.3.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.0.preact_bna/bn.weight', 'module.decoder.np.u2.dense.units.3.preact_bna/bn.weight', 'module.decoder.np.u3.dense.blk_bna.bn.num_batches_tracked', 'module.d3.units.0.conv3.weight', 'module.decoder.np.u2.dense.units.1.preact_bna/bn.running_mean', 'module.decoder.np.u3.dense.units.1.conv1/bn.num_batches_tracked', 'module.decoder.hv.u2.dense.units.2.preact_bna/bn.running_mean', 'module.decoder.np.u3.dense.units.4.preact_bna/bn.running_mean', 'module.decoder.np.u0.bn.num_batches_tracked', 'module.d2.units.2.conv2/bn.weight', 'module.d2.units.0.conv2/bn.weight', 'module.decoder.hv.u3.dense.units.5.preact_bna/bn.weight', 'module.decoder.hv.u2.dense.units.2.preact_bna/bn.bias', 'module.decoder.np.u2.dense.units.1.conv2.weight', 'module.d0.units.2.conv2/bn.running_mean', 'module.d0.units.0.conv1/bn.running_mean', 'module.decoder.hv.u2.dense.units.3.conv1/bn.num_batches_tracked', 'module.decoder.tp.u3.dense.units.1.conv1/bn.num_batches_tracked', 'module.d3.units.2.preact/bn.weight'}\n",
      "🔍 Keys in Custom but not in Original:\n",
      "{'decoder.np.u2.dense.units.3.conv1/bn.running_var', 'decoder.hv.u3.dense.units.3.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.4.conv1/bn.num_batches_tracked', 'd3.units.2.conv1.weight', 'decoder.tp.u2.dense.units.3.preact_bna/bn.running_var', 'd2.units.5.conv1/bn.running_var', 'd2.units.1.conv2/bn.running_mean', 'd2.units.4.preact/bn.running_mean', 'decoder.np.u2.dense.units.2.conv1/bn.running_var', 'd1.units.1.conv3.weight', 'decoder.np.u2.dense.units.2.conv1.weight', 'decoder.hv.u2.dense.units.1.conv2.weight', 'decoder.np.u0.bn.running_mean', 'decoder.hv.u3.dense.blk_bna.bn.running_mean', 'd0.units.1.conv2/bn.num_batches_tracked', 'd1.units.3.preact/bn.bias', 'decoder.tp.u2.dense.blk_bna.bn.running_mean', 'd2.units.2.conv1/bn.weight', 'decoder.tp.u2.dense.units.3.conv1/bn.running_var', 'decoder.tp.u3.dense.units.2.conv1/bn.weight', 'decoder.np.u3.dense.units.1.conv1.weight', 'decoder.hv.u3.dense.units.7.preact_bna/bn.bias', 'd0.units.2.conv1/bn.bias', 'decoder.hv.u3.dense.units.6.conv1.weight', 'd1.units.0.conv2/bn.num_batches_tracked', 'd3.units.2.conv1/bn.num_batches_tracked', 'd3.units.0.conv3.weight', 'decoder.np.u3.dense.units.4.conv1/bn.bias', 'd0.units.1.conv2/bn.bias', 'decoder.hv.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.2.conv1/bn.bias', 'decoder.tp.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'd0.units.1.conv3.weight', 'decoder.np.u3.dense.units.2.conv1/bn.weight', 'decoder.hv.u3.dense.units.2.conv2.weight', 'd1.units.0.conv1/bn.running_var', 'd1.blk_bna.bn.num_batches_tracked', 'decoder.hv.u3.dense.blk_bna.bn.weight', 'd2.units.1.conv1/bn.weight', 'decoder.tp.u2.dense.units.3.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'd2.units.4.conv1/bn.running_var', 'decoder.hv.u3.dense.units.2.conv1/bn.running_mean', 'd1.units.2.preact/bn.running_mean', 'decoder.hv.u2.dense.units.3.preact_bna/bn.bias', 'decoder.hv.u3.dense.units.1.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.7.conv1.weight', 'decoder.np.u3.dense.units.3.preact_bna/bn.bias', 'decoder.hv.u0.bn.running_var', 'decoder.hv.u2.dense.units.3.conv1/bn.running_mean', 'd1.units.3.preact/bn.num_batches_tracked', 'd1.units.3.preact/bn.running_var', 'd1.units.3.conv1.weight', 'decoder.np.u3.dense.units.6.conv1/bn.weight', 'd3.units.1.conv1/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.1.conv2.weight', 'decoder.np.u2.dense.units.1.conv1/bn.weight', 'd1.shortcut.weight', 'd0.units.2.conv1/bn.running_var', 'decoder.np.u3.dense.units.2.preact_bna/bn.bias', 'decoder.tp.u3.dense.units.6.conv1.weight', 'decoder.tp.u3.dense.units.4.preact_bna/bn.weight', 'decoder.tp.u1.conva.weight', 'd2.units.2.conv2/bn.bias', 'd3.units.1.conv2/bn.running_var', 'decoder.tp.u3.dense.units.4.conv1/bn.running_var', 'decoder.hv.u2.dense.units.0.conv1/bn.running_var', 'd2.units.3.conv2.weight', 'decoder.tp.u2.dense.units.0.preact_bna/bn.weight', 'decoder.hv.u2.dense.units.3.conv2.weight', 'decoder.hv.u2.dense.units.2.preact_bna/bn.running_mean', 'decoder.hv.u3.dense.units.6.preact_bna/bn.running_mean', 'd2.units.3.preact/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.2.conv1/bn.weight', 'decoder.hv.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.blk_bna.bn.weight', 'decoder.tp.u3.dense.units.3.conv1/bn.weight', 'd2.units.2.preact/bn.running_mean', 'd0.units.2.conv1/bn.running_mean', 'decoder.hv.u2.dense.units.3.conv1/bn.bias', 'upsample2x.unpool_mat', 'decoder.np.u2.dense.units.1.conv2.weight', 'd1.units.2.conv2/bn.running_var', 'd0.units.2.preact/bn.num_batches_tracked', 'd3.units.0.conv2/bn.bias', 'decoder.hv.u3.dense.units.0.conv1/bn.weight', 'decoder.tp.u3.dense.units.4.conv1/bn.bias', 'decoder.hv.u3.dense.units.3.conv1/bn.running_mean', 'decoder.hv.u2.dense.units.3.preact_bna/bn.running_var', 'decoder.hv.u2.dense.units.0.preact_bna/bn.weight', 'decoder.tp.u3.dense.units.0.conv2.weight', 'decoder.np.u3.dense.units.1.conv1/bn.running_mean', 'd2.units.2.conv1/bn.num_batches_tracked', 'd3.units.1.preact/bn.bias', 'd3.units.2.preact/bn.bias', 'decoder.np.u3.dense.units.0.conv1/bn.num_batches_tracked', 'd1.blk_bna.bn.weight', 'd0.units.2.conv1/bn.weight', 'd0.units.0.conv3.weight', 'decoder.np.u3.dense.units.0.conv2.weight', 'decoder.hv.u3.dense.units.5.preact_bna/bn.bias', 'decoder.hv.u3.dense.units.2.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.6.conv1/bn.running_mean', 'decoder.tp.u3.dense.units.7.conv1/bn.running_mean', 'd1.units.3.conv2/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.4.conv1.weight', 'decoder.np.u2.dense.units.3.conv2.weight', 'decoder.hv.u2.dense.units.1.preact_bna/bn.weight', 'decoder.np.u2.dense.units.0.preact_bna/bn.bias', 'decoder.tp.u2.dense.units.1.conv1/bn.weight', 'd2.units.3.conv2/bn.num_batches_tracked', 'decoder.np.u2.dense.units.2.preact_bna/bn.num_batches_tracked', 'd0.units.2.conv2/bn.running_var', 'decoder.np.u3.dense.units.6.conv1/bn.bias', 'decoder.tp.u2.dense.units.1.conv1/bn.bias', 'decoder.np.u3.dense.units.0.preact_bna/bn.running_var', 'decoder.tp.u2.dense.units.0.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.1.conv1/bn.running_var', 'd1.blk_bna.bn.running_mean', 'd0.units.2.conv1.weight', 'd2.units.5.conv2/bn.weight', 'decoder.np.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'd1.units.1.conv1/bn.running_var', 'd2.units.3.conv2/bn.weight', 'decoder.tp.u2.dense.units.0.preact_bna/bn.bias', 'decoder.hv.u3.dense.units.6.conv1/bn.running_var', 'd2.units.2.preact/bn.bias', 'decoder.hv.u2.dense.units.2.conv1/bn.weight', 'decoder.hv.u2.dense.units.3.conv1.weight', 'decoder.np.u2.dense.units.1.conv1.weight', 'decoder.hv.u3.dense.units.7.conv2.weight', 'decoder.np.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'decoder.np.u3.dense.units.1.conv1/bn.bias', 'd0.units.0.conv2/bn.weight', 'd1.units.3.conv2/bn.running_mean', 'decoder.tp.u2.dense.units.1.conv1/bn.running_var', 'd2.units.5.conv2/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.6.preact_bna/bn.running_var', 'conv0.bn.running_mean', 'd2.units.1.conv2/bn.weight', 'decoder.tp.u2.dense.units.2.preact_bna/bn.running_mean', 'decoder.hv.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'd3.shortcut.weight', 'decoder.np.u2.dense.blk_bna.bn.running_var', 'decoder.np.u2.dense.units.0.conv1/bn.bias', 'decoder.tp.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.4.conv2.weight', 'decoder.hv.u2.dense.units.0.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.5.conv1/bn.bias', 'decoder.hv.u2.dense.units.3.preact_bna/bn.weight', 'd0.units.2.preact/bn.running_var', 'd1.units.1.conv2.weight', 'decoder.hv.u3.dense.units.2.conv1/bn.running_var', 'decoder.hv.u3.dense.units.1.conv1/bn.num_batches_tracked', 'decoder.hv.u0.bn.num_batches_tracked', 'd0.units.2.conv2/bn.num_batches_tracked', 'decoder.hv.u2.dense.units.3.preact_bna/bn.running_mean', 'decoder.hv.u2.dense.units.3.conv1/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.0.preact_bna/bn.running_mean', 'd0.shortcut.weight', 'decoder.tp.u3.dense.units.2.preact_bna/bn.running_var', 'decoder.np.u2.dense.units.0.conv1/bn.running_mean', 'decoder.tp.u3.dense.units.5.conv1/bn.weight', 'decoder.np.u3.dense.units.2.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.1.preact_bna/bn.weight', 'd2.units.1.conv3.weight', 'decoder.tp.u3.dense.units.0.preact_bna/bn.running_var', 'decoder.tp.u2.dense.units.1.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.0.conv1/bn.weight', 'decoder.tp.u3.dense.units.1.conv2.weight', 'd3.blk_bna.bn.weight', 'decoder.np.u2.dense.units.1.preact_bna/bn.bias', 'd0.units.0.conv1/bn.bias', 'd3.units.0.conv2/bn.num_batches_tracked', 'd1.units.1.conv2/bn.running_mean', 'decoder.hv.u3.dense.units.6.conv2.weight', 'd2.units.4.preact/bn.running_var', 'decoder.np.u3.dense.units.1.preact_bna/bn.bias', 'd2.units.2.conv3.weight', 'd0.units.1.conv1/bn.running_mean', 'decoder.tp.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.3.preact_bna/bn.running_var', 'd2.units.0.conv1/bn.weight', 'decoder.np.u3.dense.units.0.conv1/bn.weight', 'decoder.np.u2.dense.blk_bna.bn.num_batches_tracked', 'decoder.hv.u3.dense.units.1.conv1/bn.running_var', 'decoder.hv.u2.dense.units.3.conv1/bn.weight', 'd0.units.2.conv2/bn.weight', 'decoder.tp.u3.dense.units.5.conv1/bn.running_var', 'd3.units.1.conv3.weight', 'd0.units.2.conv3.weight', 'd1.units.1.preact/bn.bias', 'd3.units.1.conv1.weight', 'decoder.hv.u3.dense.units.5.conv1/bn.running_var', 'decoder.hv.u2.dense.units.3.conv1/bn.running_var', 'decoder.np.u3.dense.units.1.preact_bna/bn.running_var', 'd2.units.1.preact/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'decoder.np.u2.dense.units.3.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.1.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.6.conv1/bn.weight', 'd3.units.1.preact/bn.running_var', 'conv_bot.weight', 'decoder.hv.u0.bn.weight', 'decoder.hv.u3.dense.units.7.preact_bna/bn.weight', 'decoder.np.u3.dense.units.1.conv2.weight', 'd0.units.1.conv1.weight', 'd1.units.2.preact/bn.running_var', 'decoder.hv.u3.dense.units.7.preact_bna/bn.running_mean', 'd3.units.1.conv2.weight', 'd0.units.1.preact/bn.running_mean', 'decoder.np.u3.dense.units.4.conv1/bn.num_batches_tracked', 'decoder.hv.u2.dense.units.2.conv2.weight', 'decoder.tp.u2.dense.units.1.conv1.weight', 'd0.units.0.conv1/bn.weight', 'd2.units.4.conv2/bn.num_batches_tracked', 'd2.units.4.preact/bn.num_batches_tracked', 'd1.units.2.preact/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.6.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.0.conv1/bn.running_mean', 'decoder.tp.u2.dense.blk_bna.bn.running_var', 'd2.units.5.preact/bn.bias', 'decoder.np.u3.dense.units.5.preact_bna/bn.running_mean', 'decoder.np.u3.dense.units.5.conv1.weight', 'decoder.tp.u3.dense.units.7.conv1/bn.weight', 'd2.shortcut.weight', 'decoder.np.u2.dense.units.0.conv1.weight', 'd2.units.0.conv2/bn.weight', 'decoder.tp.u3.dense.units.2.conv1/bn.running_var', 'decoder.np.u3.dense.units.3.conv1/bn.bias', 'decoder.hv.u2.dense.units.2.preact_bna/bn.running_var', 'd2.units.5.conv3.weight', 'decoder.hv.u3.convf.weight', 'd3.units.2.conv3.weight', 'decoder.np.u3.dense.units.6.conv2.weight', 'decoder.tp.u3.dense.units.7.conv1.weight', 'decoder.np.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.3.preact_bna/bn.bias', 'decoder.np.u2.dense.units.2.preact_bna/bn.running_mean', 'decoder.tp.u2.dense.units.2.conv1/bn.running_mean', 'd2.units.3.conv1/bn.running_var', 'decoder.hv.u3.dense.units.6.conv1/bn.bias', 'd1.units.2.conv2.weight', 'decoder.hv.u3.dense.units.2.preact_bna/bn.running_mean', 'decoder.hv.u2.dense.units.1.conv1/bn.weight', 'decoder.hv.u3.dense.units.7.conv1/bn.weight', 'decoder.np.u3.dense.units.2.conv1/bn.bias', 'd3.blk_bna.bn.num_batches_tracked', 'decoder.np.u3.dense.units.2.preact_bna/bn.weight', 'decoder.tp.u3.dense.units.0.preact_bna/bn.running_mean', 'd2.units.4.conv2/bn.running_mean', 'd3.units.0.conv1/bn.weight', 'decoder.np.u2.dense.units.1.preact_bna/bn.running_mean', 'd2.units.1.conv1/bn.running_var', 'd2.units.3.conv1.weight', 'd2.units.4.conv2/bn.bias', 'd0.units.1.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.7.conv1/bn.bias', 'decoder.np.u2.dense.units.1.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.7.conv1/bn.bias', 'decoder.np.u3.dense.units.2.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.blk_bna.bn.running_mean', 'decoder.tp.u0.conv.bias', 'decoder.hv.u3.dense.units.7.conv1/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.1.preact_bna/bn.running_mean', 'd1.units.1.conv1.weight', 'decoder.tp.u2.dense.units.2.preact_bna/bn.bias', 'decoder.np.u2.dense.units.0.conv1/bn.num_batches_tracked', 'd2.units.2.conv1/bn.bias', 'decoder.tp.u3.dense.units.0.preact_bna/bn.bias', 'd2.units.3.preact/bn.running_var', 'decoder.tp.u2.dense.units.3.preact_bna/bn.bias', 'decoder.np.u3.dense.units.2.conv1.weight', 'd1.units.3.conv1/bn.running_var', 'd3.units.0.conv1/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.0.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.1.conv1.weight', 'decoder.hv.u2.dense.units.1.conv1/bn.bias', 'd1.units.1.conv1/bn.bias', 'decoder.tp.u2.dense.units.0.conv1.weight', 'decoder.tp.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'd0.units.0.conv1/bn.running_mean', 'd1.units.3.conv2/bn.weight', 'd2.units.5.conv2/bn.running_var', 'd3.units.1.conv1/bn.running_var', 'decoder.tp.u2.dense.units.3.conv1/bn.running_mean', 'decoder.np.u0.bn.num_batches_tracked', 'decoder.np.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'd2.units.2.conv1.weight', 'd3.units.1.preact/bn.running_mean', 'decoder.np.u3.dense.units.0.conv1/bn.bias', 'd2.units.1.preact/bn.running_var', 'decoder.np.u2.conva.weight', 'd3.units.2.conv1/bn.running_var', 'decoder.tp.u3.dense.units.6.conv1/bn.weight', 'decoder.tp.u3.dense.units.7.preact_bna/bn.running_mean', 'd3.units.2.preact/bn.running_var', 'decoder.tp.u3.dense.units.3.conv1/bn.running_mean', 'decoder.np.u3.dense.units.7.conv1/bn.running_var', 'decoder.np.u3.dense.blk_bna.bn.weight', 'decoder.np.u2.dense.units.3.conv1/bn.bias', 'decoder.np.u2.dense.units.2.conv1/bn.bias', 'decoder.hv.u3.dense.units.6.conv1/bn.running_mean', 'decoder.np.u2.dense.units.1.conv1/bn.bias', 'decoder.tp.u2.dense.units.2.preact_bna/bn.weight', 'decoder.hv.u2.dense.units.0.preact_bna/bn.num_batches_tracked', 'conv0.bn.weight', 'd2.units.2.preact/bn.running_var', 'decoder.np.u3.dense.units.0.preact_bna/bn.bias', 'decoder.np.u3.dense.units.1.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.4.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.4.preact_bna/bn.running_mean', 'd0.blk_bna.bn.num_batches_tracked', 'decoder.tp.u3.dense.units.2.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.0.conv1/bn.num_batches_tracked', 'd2.units.3.conv2/bn.running_mean', 'd3.units.1.conv2/bn.num_batches_tracked', 'decoder.np.u3.dense.units.0.conv1/bn.running_var', 'decoder.np.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'decoder.np.u2.convf.weight', 'decoder.hv.u3.dense.units.2.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.1.conv1/bn.bias', 'd3.units.2.preact/bn.running_mean', 'decoder.tp.u2.dense.blk_bna.bn.weight', 'decoder.np.u3.dense.units.7.preact_bna/bn.weight', 'd1.units.3.conv1/bn.bias', 'd3.units.2.conv1/bn.running_mean', 'decoder.np.u3.convf.weight', 'decoder.np.u3.dense.units.5.conv2.weight', 'decoder.hv.u3.dense.units.0.preact_bna/bn.running_var', 'decoder.hv.u2.dense.units.1.conv1/bn.num_batches_tracked', 'd0.units.1.conv2/bn.running_var', 'd0.units.2.preact/bn.weight', 'decoder.tp.u3.dense.units.5.preact_bna/bn.running_mean', 'decoder.np.u3.dense.units.5.conv1/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.3.conv2.weight', 'decoder.tp.u2.dense.units.1.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'd2.units.2.conv2/bn.running_var', 'd2.units.5.preact/bn.running_mean', 'd2.units.5.conv1.weight', 'd2.units.5.conv2/bn.running_mean', 'decoder.hv.u3.dense.units.4.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.4.conv1/bn.weight', 'decoder.tp.u3.conva.weight', 'decoder.tp.u3.dense.units.0.conv1.weight', 'd1.units.0.conv1.weight', 'd2.units.1.conv1.weight', 'd1.units.3.conv2.weight', 'decoder.hv.u2.dense.units.0.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.7.conv2.weight', 'decoder.tp.u3.dense.units.2.conv1.weight', 'd2.units.3.conv2/bn.bias', 'd2.units.5.conv1/bn.running_mean', 'd0.blk_bna.bn.bias', 'd2.units.5.preact/bn.weight', 'decoder.hv.u2.dense.units.1.conv1/bn.running_mean', 'd1.units.0.conv3.weight', 'decoder.tp.u3.dense.units.1.conv1.weight', 'd1.units.0.conv1/bn.bias', 'decoder.tp.u3.dense.units.6.conv1/bn.running_var', 'decoder.np.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'd0.units.1.preact/bn.running_var', 'd3.units.0.conv1/bn.running_var', 'decoder.np.u3.dense.units.7.conv1/bn.running_mean', 'decoder.hv.u2.dense.units.2.conv1/bn.bias', 'd3.units.1.preact/bn.weight', 'decoder.np.u2.dense.units.2.preact_bna/bn.bias', 'decoder.np.u3.dense.units.3.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.7.conv1/bn.num_batches_tracked', 'decoder.np.u2.dense.blk_bna.bn.running_mean', 'decoder.hv.u3.dense.units.2.preact_bna/bn.bias', 'd2.units.1.conv2/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.0.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.1.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.3.conv1/bn.weight', 'd1.units.1.conv2/bn.num_batches_tracked', 'd2.units.0.conv1/bn.running_mean', 'd3.units.1.conv2/bn.running_mean', 'decoder.tp.u3.dense.units.3.conv1/bn.running_var', 'decoder.np.u2.dense.units.0.conv1/bn.weight', 'decoder.tp.u3.dense.units.3.conv1/bn.bias', 'd2.units.4.conv1/bn.running_mean', 'decoder.np.u3.dense.units.5.preact_bna/bn.running_var', 'd3.units.2.conv2.weight', 'decoder.hv.u2.dense.blk_bna.bn.running_var', 'd2.units.3.preact/bn.weight', 'decoder.tp.u3.dense.units.0.conv1/bn.bias', 'decoder.np.u3.dense.units.5.preact_bna/bn.bias', 'decoder.np.u2.dense.units.2.preact_bna/bn.running_var', 'd0.units.1.conv1/bn.bias', 'd0.units.1.conv2/bn.running_mean', 'decoder.tp.u3.dense.units.7.conv1/bn.running_var', 'decoder.tp.u0.bn.bias', 'decoder.np.u3.dense.units.3.conv1/bn.weight', 'decoder.hv.u3.dense.units.5.conv1/bn.num_batches_tracked', 'decoder.hv.u0.conv.weight', 'decoder.np.u2.dense.units.3.conv1/bn.weight', 'decoder.tp.u2.dense.units.3.conv1/bn.weight', 'd1.units.2.conv2/bn.num_batches_tracked', 'decoder.np.u3.dense.units.7.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'decoder.np.u3.dense.units.4.conv1/bn.running_var', 'decoder.tp.u2.dense.units.0.preact_bna/bn.running_mean', 'd3.blk_bna.bn.running_var', 'decoder.hv.u3.dense.blk_bna.bn.num_batches_tracked', 'd0.units.0.conv2/bn.num_batches_tracked', 'd0.units.2.preact/bn.bias', 'decoder.tp.u2.dense.units.0.conv1/bn.weight', 'decoder.np.u3.dense.units.6.preact_bna/bn.running_mean', 'd3.units.2.conv1/bn.weight', 'decoder.np.u2.dense.units.1.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.5.preact_bna/bn.num_batches_tracked', 'decoder.np.u3.dense.units.5.conv1/bn.bias', 'decoder.np.u3.dense.units.2.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'd2.units.3.preact/bn.running_mean', 'decoder.tp.u3.dense.units.1.preact_bna/bn.bias', 'decoder.np.u2.dense.units.0.preact_bna/bn.running_var', 'd2.units.0.conv2/bn.bias', 'decoder.hv.u3.dense.units.1.conv1/bn.bias', 'decoder.tp.u2.dense.units.2.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.7.conv1/bn.running_var', 'decoder.np.u2.dense.units.0.preact_bna/bn.running_mean', 'decoder.np.u2.dense.units.3.conv1/bn.num_batches_tracked', 'd0.units.1.preact/bn.weight', 'decoder.tp.u0.bn.running_mean', 'decoder.hv.u3.dense.units.4.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.2.conv1/bn.running_var', 'decoder.hv.u2.dense.blk_bna.bn.running_mean', 'd1.units.2.conv2/bn.weight', 'decoder.np.u3.dense.units.4.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.0.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.1.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.1.preact_bna/bn.weight', 'decoder.tp.u3.dense.units.6.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.0.conv1.weight', 'd3.units.1.conv1/bn.bias', 'd2.units.2.conv2/bn.num_batches_tracked', 'd3.units.0.conv2/bn.running_var', 'decoder.hv.u3.dense.units.3.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.units.0.preact_bna/bn.running_mean', 'decoder.np.u3.dense.units.6.preact_bna/bn.weight', 'd1.units.3.conv3.weight', 'd2.units.0.conv2/bn.running_mean', 'd1.units.2.conv1/bn.num_batches_tracked', 'd2.units.0.conv2.weight', 'decoder.np.u3.dense.units.4.conv1/bn.running_mean', 'd2.units.3.conv3.weight', 'decoder.np.u3.dense.units.7.preact_bna/bn.num_batches_tracked', 'decoder.hv.u0.bn.running_mean', 'd2.units.1.conv2.weight', 'd0.units.1.preact/bn.bias', 'decoder.tp.u2.dense.units.1.preact_bna/bn.bias', 'd1.units.1.preact/bn.running_mean', 'decoder.hv.u3.dense.units.3.conv1.weight', 'decoder.tp.u2.dense.units.0.conv1/bn.bias', 'd1.units.0.conv2/bn.running_mean', 'd2.blk_bna.bn.bias', 'd1.units.1.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.5.preact_bna/bn.weight', 'decoder.tp.u2.convf.weight', 'decoder.tp.u3.dense.units.5.preact_bna/bn.bias', 'd1.units.2.conv1/bn.weight', 'd0.units.1.conv1/bn.running_var', 'd0.blk_bna.bn.running_mean', 'decoder.hv.u3.dense.units.3.preact_bna/bn.weight', 'decoder.np.u3.dense.units.7.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.1.conv1/bn.weight', 'decoder.np.u3.dense.units.4.conv2.weight', 'decoder.np.u0.bn.weight', 'decoder.hv.u3.dense.units.5.conv1/bn.bias', 'd2.units.1.preact/bn.running_mean', 'd1.units.1.conv1/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.3.preact_bna/bn.weight', 'd1.units.0.conv2/bn.bias', 'd1.units.3.preact/bn.weight', 'd2.units.2.conv2.weight', 'd3.units.0.conv2/bn.running_mean', 'decoder.np.u2.dense.units.2.conv1/bn.weight', 'decoder.np.u3.dense.blk_bna.bn.bias', 'd2.units.5.conv1/bn.weight', 'decoder.np.u3.dense.units.7.conv2.weight', 'decoder.hv.u3.dense.units.2.preact_bna/bn.num_batches_tracked', 'decoder.hv.u2.dense.units.1.conv1/bn.running_var', 'decoder.tp.u3.dense.units.4.preact_bna/bn.bias', 'decoder.tp.u0.bn.weight', 'd1.blk_bna.bn.bias', 'decoder.hv.u3.dense.units.1.conv1/bn.weight', 'd0.units.1.conv2/bn.weight', 'd2.units.0.conv2/bn.num_batches_tracked', 'decoder.np.u3.dense.units.2.preact_bna/bn.running_mean', 'decoder.np.u3.dense.units.3.conv1/bn.running_var', 'd0.units.0.conv2/bn.bias', 'd2.units.3.conv1/bn.weight', 'decoder.tp.u2.dense.blk_bna.bn.bias', 'd1.units.1.conv2/bn.weight', 'decoder.tp.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'd2.units.3.preact/bn.bias', 'd1.units.3.preact/bn.running_mean', 'd2.units.2.preact/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.4.conv1/bn.weight', 'd3.units.1.preact/bn.num_batches_tracked', 'decoder.np.u2.dense.units.3.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'decoder.np.u2.dense.units.1.conv1/bn.running_var', 'd3.units.0.conv2/bn.weight', 'd2.units.2.preact/bn.weight', 'decoder.hv.u2.dense.units.2.preact_bna/bn.weight', 'd1.units.0.conv2/bn.weight', 'decoder.hv.u3.dense.units.4.conv1/bn.running_var', 'd1.units.2.preact/bn.bias', 'd2.units.0.conv2/bn.running_var', 'decoder.tp.u3.dense.units.6.conv1/bn.num_batches_tracked', 'd1.units.3.conv1/bn.num_batches_tracked', 'decoder.tp.u2.dense.units.0.conv1/bn.running_var', 'd3.units.1.conv1/bn.running_mean', 'd1.units.0.conv2.weight', 'decoder.hv.u3.dense.units.6.preact_bna/bn.running_var', 'd0.units.2.conv2/bn.bias', 'decoder.np.u3.dense.units.3.conv1.weight', 'decoder.hv.u3.dense.units.4.preact_bna/bn.bias', 'decoder.tp.u3.dense.units.3.conv1.weight', 'd0.units.2.conv2.weight', 'decoder.hv.u3.dense.units.2.conv1/bn.weight', 'decoder.tp.u3.dense.blk_bna.bn.running_var', 'decoder.hv.u2.dense.blk_bna.bn.bias', 'd3.units.1.conv2/bn.weight', 'decoder.np.u2.dense.units.1.conv1/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.1.preact_bna/bn.num_batches_tracked', 'd1.units.1.preact/bn.running_var', 'd2.units.1.conv1/bn.running_mean', 'decoder.np.u3.dense.units.6.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.5.conv2.weight', 'd1.units.3.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.4.conv1.weight', 'decoder.np.u3.dense.units.2.conv2.weight', 'decoder.tp.u3.dense.units.3.preact_bna/bn.weight', 'decoder.hv.u1.conva.weight', 'd1.units.2.conv1.weight', 'decoder.np.u3.dense.units.0.conv1.weight', 'decoder.hv.u2.dense.units.2.conv1/bn.running_mean', 'decoder.tp.u3.dense.units.6.preact_bna/bn.bias', 'decoder.hv.u3.dense.units.7.preact_bna/bn.running_var', 'd2.units.5.preact/bn.running_var', 'decoder.tp.u3.dense.units.1.preact_bna/bn.weight', 'decoder.tp.u0.conv.weight', 'decoder.hv.u2.dense.units.0.conv1/bn.running_mean', 'd1.units.2.preact/bn.weight', 'decoder.hv.u2.dense.blk_bna.bn.num_batches_tracked', 'decoder.hv.u3.dense.units.0.conv1/bn.bias', 'd1.units.3.conv1/bn.weight', 'd2.units.2.conv2/bn.weight', 'decoder.np.u3.dense.units.3.conv1/bn.running_mean', 'decoder.tp.u3.convf.weight', 'decoder.np.u3.dense.units.7.preact_bna/bn.bias', 'decoder.np.u0.conv.weight', 'decoder.hv.u3.dense.units.4.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.3.conv2.weight', 'decoder.np.u1.conva.weight', 'd2.units.3.conv1/bn.bias', 'decoder.tp.u3.dense.units.7.preact_bna/bn.bias', 'decoder.hv.u2.dense.units.0.preact_bna/bn.running_mean', 'decoder.np.u3.dense.units.4.conv1/bn.weight', 'decoder.hv.u3.dense.units.1.conv2.weight', 'decoder.hv.u3.dense.blk_bna.bn.bias', 'decoder.tp.u2.dense.units.1.conv1/bn.running_mean', 'd1.units.2.conv1/bn.bias', 'd2.units.4.conv2/bn.running_var', 'decoder.np.u2.dense.units.3.preact_bna/bn.bias', 'd1.units.2.conv2/bn.running_mean', 'decoder.hv.u3.dense.units.0.preact_bna/bn.bias', 'decoder.tp.u2.dense.units.0.conv2.weight', 'decoder.tp.u3.dense.units.4.conv1/bn.running_mean', 'decoder.tp.u2.dense.units.3.conv1.weight', 'decoder.hv.u3.dense.units.0.conv1/bn.running_var', 'decoder.tp.u2.dense.units.2.conv2.weight', 'decoder.np.u0.conv.bias', 'decoder.tp.u2.dense.units.1.preact_bna/bn.running_var', 'd1.units.0.conv1/bn.num_batches_tracked', 'd3.units.1.conv1/bn.weight', 'decoder.hv.u2.dense.units.0.conv1.weight', 'decoder.tp.u2.dense.units.2.conv1/bn.running_var', 'decoder.hv.u3.dense.units.0.conv2.weight', 'd1.units.0.conv1/bn.weight', 'decoder.hv.u2.dense.units.2.preact_bna/bn.bias', 'd0.units.1.conv2.weight', 'decoder.np.u3.dense.units.4.preact_bna/bn.bias', 'decoder.tp.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'd1.units.1.conv2/bn.running_var', 'd3.units.2.conv2/bn.bias', 'decoder.hv.u2.dense.units.1.preact_bna/bn.running_mean', 'decoder.hv.u2.dense.units.0.conv2.weight', 'd0.units.0.conv2/bn.running_mean', 'd2.units.2.conv2/bn.running_mean', 'd3.units.0.conv1/bn.bias', 'd0.units.1.conv1/bn.weight', 'd0.units.2.conv1/bn.num_batches_tracked', 'd2.units.0.conv1/bn.bias', 'decoder.tp.u3.dense.blk_bna.bn.running_mean', 'decoder.hv.u3.dense.units.3.conv1/bn.bias', 'decoder.hv.u3.dense.units.2.conv1/bn.bias', 'd1.units.0.conv2/bn.running_var', 'decoder.tp.u3.dense.units.7.preact_bna/bn.weight', 'decoder.hv.u2.dense.units.2.conv1.weight', 'decoder.tp.u3.dense.units.0.conv1/bn.running_mean', 'decoder.hv.u2.dense.units.2.conv1/bn.num_batches_tracked', 'decoder.np.u3.dense.blk_bna.bn.running_var', 'decoder.np.u3.dense.units.7.conv1.weight', 'd3.units.0.conv1/bn.running_mean', 'decoder.tp.u2.dense.units.3.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.2.conv2.weight', 'd2.units.4.preact/bn.weight', 'd2.units.4.conv1.weight', 'decoder.tp.u3.dense.units.6.conv1/bn.bias', 'd0.units.0.conv2/bn.running_var', 'd0.units.2.conv2/bn.running_mean', 'd1.units.3.conv2/bn.bias', 'decoder.tp.u3.dense.blk_bna.bn.num_batches_tracked', 'decoder.np.u3.dense.units.5.conv1/bn.running_var', 'decoder.np.u3.dense.units.6.conv1/bn.running_mean', 'decoder.np.u3.dense.units.4.preact_bna/bn.running_var', 'd2.units.4.conv1/bn.weight', 'decoder.np.u2.dense.units.2.conv1/bn.num_batches_tracked', 'decoder.np.u2.dense.units.0.conv1/bn.running_var', 'd1.units.3.conv2/bn.running_var', 'decoder.hv.u2.dense.units.0.conv1/bn.bias', 'decoder.tp.u3.dense.units.3.preact_bna/bn.bias', 'decoder.np.u2.dense.units.0.preact_bna/bn.weight', 'decoder.np.u3.dense.units.1.preact_bna/bn.running_mean', 'd2.units.0.conv1/bn.running_var', 'd2.units.5.conv2.weight', 'd2.units.3.conv1/bn.num_batches_tracked', 'd3.units.1.conv2/bn.bias', 'decoder.tp.u3.dense.units.6.conv2.weight', 'decoder.hv.u3.dense.units.6.preact_bna/bn.bias', 'decoder.hv.u2.dense.units.1.conv1.weight', 'd3.units.2.preact/bn.num_batches_tracked', 'decoder.np.u3.dense.units.4.conv1.weight', 'decoder.tp.u3.dense.units.3.conv2.weight', 'decoder.hv.u3.dense.units.3.conv1/bn.running_var', 'decoder.hv.u3.dense.units.3.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.0.conv1/bn.num_batches_tracked', 'decoder.tp.u0.bn.running_var', 'decoder.hv.u3.dense.units.5.conv2.weight', 'd3.units.2.preact/bn.weight', 'd0.units.1.preact/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.1.conv1/bn.running_mean', 'decoder.tp.u3.dense.units.3.conv1/bn.num_batches_tracked', 'decoder.tp.u0.bn.num_batches_tracked', 'd2.units.4.preact/bn.bias', 'decoder.np.u2.dense.units.2.preact_bna/bn.weight', 'decoder.tp.u2.dense.units.1.preact_bna/bn.running_mean', 'd1.units.2.conv1/bn.running_var', 'd2.units.0.conv1.weight', 'd2.units.2.conv1/bn.running_mean', 'd1.units.1.preact/bn.num_batches_tracked', 'd1.units.2.conv3.weight', 'decoder.tp.u3.dense.units.2.preact_bna/bn.bias', 'decoder.np.u3.dense.units.7.conv1/bn.weight', 'decoder.hv.u3.dense.units.4.preact_bna/bn.running_var', 'decoder.hv.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.2.conv1/bn.running_mean', 'decoder.hv.u2.dense.blk_bna.bn.weight', 'decoder.np.u3.conva.weight', 'decoder.tp.u3.dense.units.4.preact_bna/bn.running_mean', 'd1.units.1.conv2/bn.bias', 'd2.units.4.conv2.weight', 'decoder.np.u3.dense.units.7.preact_bna/bn.running_var', 'decoder.tp.u3.dense.units.4.preact_bna/bn.num_batches_tracked', 'decoder.np.u2.dense.blk_bna.bn.weight', 'decoder.hv.u3.dense.units.6.preact_bna/bn.weight', 'd2.units.1.conv2/bn.bias', 'decoder.np.u2.dense.units.3.preact_bna/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.1.preact_bna/bn.running_mean', 'decoder.tp.u3.dense.units.6.preact_bna/bn.running_mean', 'decoder.np.u2.dense.units.2.conv2.weight', 'decoder.hv.u0.bn.bias', 'd0.units.2.preact/bn.running_mean', 'd2.units.1.preact/bn.bias', 'decoder.hv.u3.dense.units.5.preact_bna/bn.running_var', 'd2.units.3.conv2/bn.running_var', 'd0.blk_bna.bn.running_var', 'd3.units.0.conv2.weight', 'decoder.tp.u3.dense.units.2.conv1/bn.num_batches_tracked', 'decoder.hv.u3.dense.blk_bna.bn.running_var', 'decoder.np.u0.bn.bias', 'decoder.tp.u3.dense.units.5.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.0.conv1/bn.running_mean', 'decoder.tp.u2.dense.units.2.conv1/bn.num_batches_tracked', 'd2.units.0.conv1/bn.num_batches_tracked', 'decoder.tp.u2.conva.weight', 'decoder.hv.u3.dense.units.2.conv1.weight', 'd2.units.1.conv2/bn.running_var', 'decoder.np.u2.dense.units.0.conv2.weight', 'd1.units.2.conv2/bn.bias', 'd2.blk_bna.bn.weight', 'decoder.hv.u2.dense.units.1.preact_bna/bn.running_var', 'decoder.tp.u3.dense.blk_bna.bn.bias', 'conv0.bn.bias', 'decoder.np.u2.dense.units.3.conv1/bn.running_mean', 'd2.units.0.conv3.weight', 'd2.units.4.conv2/bn.weight', 'd2.units.2.conv1/bn.running_var', 'd1.units.0.conv1/bn.running_mean', 'decoder.hv.u3.dense.units.5.preact_bna/bn.running_mean', 'd2.units.4.conv1/bn.bias', 'decoder.np.u0.bn.running_var', 'decoder.tp.u3.dense.units.5.conv1.weight', 'd2.units.5.conv1/bn.num_batches_tracked', 'decoder.hv.u2.dense.units.0.conv1/bn.weight', 'conv0.bn.num_batches_tracked', 'decoder.tp.u2.dense.blk_bna.bn.num_batches_tracked', 'd2.units.5.conv2/bn.bias', 'decoder.hv.u3.dense.units.4.conv1/bn.bias', 'decoder.hv.u3.dense.units.6.preact_bna/bn.num_batches_tracked', 'decoder.np.u3.dense.units.5.preact_bna/bn.weight', 'conv0.bn.running_var', 'decoder.np.u2.dense.units.3.preact_bna/bn.weight', 'd2.units.1.conv1/bn.bias', 'decoder.tp.u3.dense.units.5.conv1/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.5.conv1/bn.running_mean', 'decoder.hv.u3.conva.weight', 'd2.units.4.conv1/bn.num_batches_tracked', 'd2.units.4.conv3.weight', 'd0.units.0.conv1.weight', 'decoder.np.u2.dense.units.2.conv1/bn.running_mean', 'd2.blk_bna.bn.num_batches_tracked', 'd1.units.2.conv1/bn.running_mean', 'decoder.np.u3.dense.units.6.preact_bna/bn.running_var', 'd2.units.5.conv1/bn.bias', 'decoder.np.u3.dense.units.0.preact_bna/bn.weight', 'decoder.hv.u3.dense.units.7.conv1/bn.running_mean', 'decoder.hv.u2.convf.weight', 'decoder.hv.u2.dense.units.2.conv1/bn.running_var', 'decoder.np.u3.dense.units.3.preact_bna/bn.num_batches_tracked', 'd2.blk_bna.bn.running_mean', 'd2.units.5.preact/bn.num_batches_tracked', 'decoder.tp.u3.dense.units.1.conv1/bn.running_var', 'decoder.np.u3.dense.units.5.conv1/bn.running_mean', 'd2.units.1.preact/bn.weight', 'd2.blk_bna.bn.running_var', 'decoder.np.u2.dense.units.3.conv1.weight', 'd2.units.1.conv1/bn.num_batches_tracked', 'd0.units.0.conv1/bn.num_batches_tracked', 'decoder.hv.u0.conv.bias', 'decoder.hv.u3.dense.units.4.conv2.weight', 'decoder.tp.u2.dense.units.3.conv1/bn.bias', 'decoder.hv.u3.dense.units.1.preact_bna/bn.bias', 'd0.blk_bna.bn.weight', 'decoder.hv.u3.dense.units.2.preact_bna/bn.weight', 'd3.blk_bna.bn.bias', 'decoder.np.u3.dense.units.5.conv1/bn.weight', 'decoder.tp.u3.dense.units.0.preact_bna/bn.weight', 'd1.units.1.conv1/bn.weight', 'd2.units.3.conv1/bn.running_mean', 'decoder.np.u3.dense.blk_bna.bn.num_batches_tracked', 'decoder.tp.u2.dense.units.2.conv1.weight', 'decoder.hv.u2.dense.units.1.preact_bna/bn.bias', 'decoder.tp.u3.dense.units.7.preact_bna/bn.running_var', 'decoder.hv.u3.dense.units.5.conv1/bn.running_mean', 'decoder.np.u3.dense.units.7.conv1/bn.bias', 'decoder.tp.u3.dense.units.2.preact_bna/bn.running_mean', 'd3.units.2.conv2/bn.running_var', 'decoder.tp.u2.dense.units.2.conv1/bn.bias', 'decoder.np.u3.dense.units.4.preact_bna/bn.weight', 'decoder.np.u3.dense.units.6.conv1/bn.running_var', 'd3.units.0.conv1.weight', 'decoder.np.u3.dense.units.3.preact_bna/bn.weight', 'decoder.np.u3.dense.units.3.preact_bna/bn.running_mean', 'decoder.hv.u3.dense.units.5.conv1.weight', 'decoder.np.u3.dense.units.3.conv1/bn.num_batches_tracked', 'decoder.np.u2.dense.blk_bna.bn.bias', 'decoder.hv.u2.dense.units.0.preact_bna/bn.bias', 'decoder.tp.u3.dense.units.3.preact_bna/bn.running_mean', 'decoder.np.u2.dense.units.1.conv1/bn.running_mean', 'd3.units.2.conv2/bn.num_batches_tracked', 'decoder.hv.u3.dense.units.0.preact_bna/bn.weight', 'd0.units.0.conv1/bn.running_var', 'd3.units.2.conv1/bn.bias', 'd0.units.0.conv2.weight', 'conv0./.weight', 'decoder.np.u3.dense.units.1.conv1/bn.weight', 'd3.units.2.conv2/bn.weight', 'decoder.np.u2.dense.units.1.preact_bna/bn.num_batches_tracked', 'decoder.np.u3.dense.units.3.conv2.weight', 'd1.units.1.preact/bn.weight', 'decoder.np.u3.dense.units.6.conv1.weight', 'decoder.tp.u3.dense.units.5.preact_bna/bn.running_var', 'd1.blk_bna.bn.running_var', 'decoder.np.u3.dense.units.6.preact_bna/bn.bias', 'decoder.hv.u2.conva.weight', 'decoder.tp.u3.dense.units.0.conv1/bn.running_var', 'd3.blk_bna.bn.running_mean', 'decoder.hv.u3.dense.units.5.conv1/bn.weight', 'd3.units.2.conv2/bn.running_mean'}\n",
      "✅ Optimizer keys match!\n",
      "✅ Scheduler keys match!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original 모델 로드\n",
    "original_path = \"/mnt/Hover-Net/Hover-Net_original/logs/05_phase1/net_epoch=1.tar\"\n",
    "original_checkpoint = torch.load(original_path, map_location='cpu')\n",
    "\n",
    "# Custom 모델 로드\n",
    "custom_path = \"/mnt/Hover-Net/Hover-Net_Custom/checkpoints/phase1_model.tar\"\n",
    "custom_checkpoint = torch.load(custom_path, map_location='cpu')\n",
    "\n",
    "# ==========================\n",
    "# 1. model_state_dict 비교\n",
    "# ==========================\n",
    "original_model_dict = original_checkpoint['desc'] if 'desc' in original_checkpoint else original_checkpoint.get('model_state_dict', {})\n",
    "custom_model_dict = custom_checkpoint.get('model_state_dict', {})\n",
    "\n",
    "original_keys = set(original_model_dict.keys())\n",
    "custom_keys = set(custom_model_dict.keys())\n",
    "\n",
    "missing_in_custom = original_keys - custom_keys\n",
    "missing_in_original = custom_keys - original_keys\n",
    "common_keys = original_keys & custom_keys\n",
    "\n",
    "# Check for missing keys\n",
    "if missing_in_custom:\n",
    "    print(\"🔍 Keys in Original but not in Custom:\")\n",
    "    print(missing_in_custom)\n",
    "\n",
    "if missing_in_original:\n",
    "    print(\"🔍 Keys in Custom but not in Original:\")\n",
    "    print(missing_in_original)\n",
    "\n",
    "# Compare common keys\n",
    "for key in common_keys:\n",
    "    if not torch.equal(original_model_dict[key], custom_model_dict[key]):\n",
    "        print(f\"❌ Weight Mismatch Found: {key}\")\n",
    "    else:\n",
    "        print(f\"✅ Weight Match: {key}\")\n",
    "\n",
    "# ==========================\n",
    "# 2. optimizer_state_dict 비교\n",
    "# ==========================\n",
    "original_optimizer = original_checkpoint.get('optimizer', original_checkpoint.get('optimizer_state_dict', {}))\n",
    "custom_optimizer = custom_checkpoint.get('optimizer_state_dict', {})\n",
    "\n",
    "if original_optimizer.keys() != custom_optimizer.keys():\n",
    "    print(\"❌ Optimizer keys do not match!\")\n",
    "    print(\"Original Optimizer Keys:\", original_optimizer.keys())\n",
    "    print(\"Custom Optimizer Keys:\", custom_optimizer.keys())\n",
    "else:\n",
    "    print(\"Original Optimizer Keys:\", original_optimizer.keys())\n",
    "    print(\"✅ Optimizer keys match!\")\n",
    "\n",
    "# ==========================\n",
    "# 3. scheduler_state_dict 비교\n",
    "# ==========================\n",
    "original_scheduler = original_checkpoint.get('lr_scheduler', original_checkpoint.get('scheduler_state_dict', {}))\n",
    "custom_scheduler = custom_checkpoint.get('scheduler_state_dict', {})\n",
    "\n",
    "if original_scheduler.keys() != custom_scheduler.keys():\n",
    "    print(\"❌ Scheduler keys do not match!\")\n",
    "    print(\"Original Scheduler Keys:\", original_scheduler.keys())\n",
    "    print(\"Custom Scheduler Keys:\", custom_scheduler.keys())\n",
    "else:\n",
    "    print(\"Original Scheduler Keys:\", original_scheduler.keys())\n",
    "    print(\"✅ Scheduler keys match!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
